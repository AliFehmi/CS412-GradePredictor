{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import os\n",
    "import tqdm\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import graphviz\n",
    "\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:15<00:00,  8.33it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/html/*.html\"\n",
    "\n",
    "code2convos = dict()\n",
    "total_code_response_list = []\n",
    "pbar = tqdm.tqdm(sorted(list(glob(data_path))))\n",
    "for path in pbar:\n",
    "    code_block_count = 0\n",
    "    file_code = os.path.basename(path).split(\".\")[0]\n",
    "    with open(path, \"r\", encoding=\"latin1\") as fh:\n",
    "        html_page = fh.read()\n",
    "        soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "\n",
    "        data_test_id_pattern = re.compile(r\"conversation-turn-[0-9]+\")\n",
    "        conversations = soup.find_all(\"div\", attrs={\"data-testid\": data_test_id_pattern})\n",
    "        convo_texts = []\n",
    "        last_user_text = None  # Keep track of the last user message\n",
    "\n",
    "        for i, convo in enumerate(conversations):\n",
    "            user_div = convo.find(\"div\", attrs={\"data-message-author-role\": \"user\"})\n",
    "            assistant_div = convo.find(\"div\", attrs={\"data-message-author-role\": \"assistant\"})\n",
    "\n",
    "            # When a user message is found, save it to last_user_text\n",
    "            if user_div:\n",
    "                last_user_text = user_div.text.strip()\n",
    "            if assistant_div and assistant_div.find(\"code\"):  # This assumes that <code> tags are used for code blocks\n",
    "                code_block_count += 1\n",
    "\n",
    "            # When an assistant message follows a user message, pair them\n",
    "            if assistant_div and last_user_text is not None:\n",
    "                convo_texts.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"text\": last_user_text,\n",
    "                    \"response\": assistant_div.text.strip()  # Pair with the last user message\n",
    "                })\n",
    "                last_user_text = None  # Reset last_user_text after pairing\n",
    "        total_code_response_list.append((file_code, code_block_count))\n",
    "        \n",
    "        code2convos[file_code] = convo_texts\n",
    "total_code_response_df = pd.DataFrame(total_code_response_list, columns=['code', 'code_responses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'response': 'You can load a CSV file into a Pandas DataFrame in Python using '\n",
      "              \"the pandas.read_csv() function. Here's how you can do it for \"\n",
      "              'your specific CSV file:pythonCopy codeimport pandas as pd\\n'\n",
      "              '\\n'\n",
      "              '# Specify the file path\\n'\n",
      "              \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "              '\\n'\n",
      "              '# Load the CSV file into a Pandas DataFrame\\n'\n",
      "              'df = pd.read_csv(file_path)\\n'\n",
      "              '\\n'\n",
      "              '# Display the first few rows of the DataFrame to verify the '\n",
      "              'data has been loaded\\n'\n",
      "              'print(df.head())\\n'\n",
      "              \"This code assumes that the CSV file 'cs412_hw1_dataset.csv' is \"\n",
      "              'in the same directory as your Python script or Jupyter '\n",
      "              'Notebook. If the file is in a different directory, you can '\n",
      "              'specify the full path to the file in the file_path variable.The '\n",
      "              'pd.read_csv() function will automatically infer the column '\n",
      "              \"names from the first row of the CSV file, so you don't need to \"\n",
      "              'explicitly specify the column names unless they are different '\n",
      "              'from what you provided. You can access columns in the DataFrame '\n",
      "              \"using their names, e.g., df['Species'], df['Island'], etc.\",\n",
      "  'role': 'user',\n",
      "  'text': 'Load a CSV file into a Pandas in Python. The file is named '\n",
      "          \"'cs412_hw1_dataset.csv' and contains columns like 'Species', \"\n",
      "          \"'Island', 'Sex', 'Diet', 'Year', 'Life Stage', 'Body Mass (g)', \"\n",
      "          \"'Bill Length (mm)', 'Bill Depth (mm)', 'Flipper Length (mm)', and \"\n",
      "          \"'Health Metrics'.\"},\n",
      " {'response': 'You can use Pandas to understand a dataset by performing '\n",
      "              \"various exploratory data analysis (EDA) tasks. Here's a Python \"\n",
      "              'code snippet that accomplishes the tasks you '\n",
      "              'mentioned:pythonCopy codeimport pandas as pd\\n'\n",
      "              '\\n'\n",
      "              '# Load the dataset into a Pandas DataFrame\\n'\n",
      "              \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "              'df = pd.read_csv(file_path)\\n'\n",
      "              '\\n'\n",
      "              '# 1. Find the shape of the dataset\\n'\n",
      "              'shape = df.shape\\n'\n",
      "              'print(\"Shape of the dataset (rows, columns):\", shape)\\n'\n",
      "              '\\n'\n",
      "              '# 2. Display variable names (column names)\\n'\n",
      "              'variable_names = df.columns\\n'\n",
      "              'print(\"Variable names (column names):\")\\n'\n",
      "              'for name in variable_names:\\n'\n",
      "              '    print(name)\\n'\n",
      "              '\\n'\n",
      "              '# 3. Display a summary of the dataset with the info() function\\n'\n",
      "              'print(\"\\\\nSummary of the dataset:\")\\n'\n",
      "              'df.info()\\n'\n",
      "              '\\n'\n",
      "              '# 4. Show the first 5 rows using the head() function\\n'\n",
      "              'print(\"\\\\nFirst 5 rows of the dataset:\")\\n'\n",
      "              'print(df.head())\\n'\n",
      "              \"Here's a breakdown of what each part of the code does:It \"\n",
      "              'calculates and prints the shape of the dataset using df.shape, '\n",
      "              'which gives you the number of rows and columns in the '\n",
      "              'DataFrame.It retrieves and prints the variable names (column '\n",
      "              'names) using df.columns.It displays a summary of the dataset, '\n",
      "              'including information about the data types, non-null counts, '\n",
      "              'and memory usage, using the df.info() function.Finally, it '\n",
      "              'displays the first 5 rows of the dataset using df.head() to '\n",
      "              'provide a glimpse of the data.You can run this code to get an '\n",
      "              'initial understanding of your dataset using Pandas.',\n",
      "  'role': 'user',\n",
      "  'text': 'Provide Python code to understand a dataset using Pandas. Find the '\n",
      "          'shape of the dataset, display variable names, display a summary of '\n",
      "          'the dataset with the info() function, and show the first 5 rows '\n",
      "          'using the head() function.'},\n",
      " {'response': 'To preprocess the dataset as per your requirements, you can '\n",
      "              'follow these steps:Check for missing values and handle '\n",
      "              'them.Encode labels with mappings using the map function.Split '\n",
      "              \"the data into training (80%) and testing (20%) sets.Here's the \"\n",
      "              'Python code to achieve this:pythonCopy codeimport pandas as pd\\n'\n",
      "              'from sklearn.model_selection import train_test_split\\n'\n",
      "              '\\n'\n",
      "              '# Load the dataset into a Pandas DataFrame\\n'\n",
      "              \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "              'df = pd.read_csv(file_path)\\n'\n",
      "              '\\n'\n",
      "              '# 1. Check for missing values and handle them\\n'\n",
      "              '# You can either drop rows with missing values or fill them '\n",
      "              'with the most common value in the column.\\n'\n",
      "              \"# In this example, we'll fill missing values with the most \"\n",
      "              'common value in each column.\\n'\n",
      "              '\\n'\n",
      "              \"# Fill missing values in the 'Sex' column with the most common \"\n",
      "              'value\\n'\n",
      "              \"most_common_sex = df['Sex'].mode()[0]\\n\"\n",
      "              \"df['Sex'].fillna(most_common_sex, inplace=True)\\n\"\n",
      "              '\\n'\n",
      "              \"# Fill missing values in the 'Island' column with the most \"\n",
      "              'common value\\n'\n",
      "              \"most_common_island = df['Island'].mode()[0]\\n\"\n",
      "              \"df['Island'].fillna(most_common_island, inplace=True)\\n\"\n",
      "              '\\n'\n",
      "              \"# Fill missing values in the 'Diet' column with the most common \"\n",
      "              'value\\n'\n",
      "              \"most_common_diet = df['Diet'].mode()[0]\\n\"\n",
      "              \"df['Diet'].fillna(most_common_diet, inplace=True)\\n\"\n",
      "              '\\n'\n",
      "              \"# Fill missing values in the 'Life Stage' column with the most \"\n",
      "              'common value\\n'\n",
      "              \"most_common_life_stage = df['Life Stage'].mode()[0]\\n\"\n",
      "              \"df['Life Stage'].fillna(most_common_life_stage, inplace=True)\\n\"\n",
      "              '\\n'\n",
      "              \"# Fill missing values in the 'Health Metrics' column with the \"\n",
      "              'most common value\\n'\n",
      "              \"most_common_health_metrics = df['Health Metrics'].mode()[0]\\n\"\n",
      "              \"df['Health Metrics'].fillna(most_common_health_metrics, \"\n",
      "              'inplace=True)\\n'\n",
      "              '\\n'\n",
      "              '# 2. Encode labels with mappings\\n'\n",
      "              \"sex_map = {'female': 1, 'male': 0}\\n\"\n",
      "              \"island_map = {'Biscoe': 1, 'Dream': 2, 'Torgensen': 3}\\n\"\n",
      "              \"diet_map = {'fish': 1, 'krill': 2, 'squid': 3, 'parental': 4}\\n\"\n",
      "              \"life_stage_map = {'chick': 1, 'juvenile': 2, 'adult': 3}\\n\"\n",
      "              \"health_metrics_map = {'healthy': 1, 'overweight': 2, \"\n",
      "              \"'underweight': 3}\\n\"\n",
      "              '\\n'\n",
      "              \"df['Sex'] = df['Sex'].map(sex_map)\\n\"\n",
      "              \"df['Island'] = df['Island'].map(island_map)\\n\"\n",
      "              \"df['Diet'] = df['Diet'].map(diet_map)\\n\"\n",
      "              \"df['Life Stage'] = df['Life Stage'].map(life_stage_map)\\n\"\n",
      "              \"df['Health Metrics'] = df['Health \"\n",
      "              \"Metrics'].map(health_metrics_map)\\n\"\n",
      "              '\\n'\n",
      "              '# 3. Split the data into training (80%) and testing (20%) sets\\n'\n",
      "              \"X = df.drop(columns=['Species'])  # Features (excluding \"\n",
      "              \"'Species' column)\\n\"\n",
      "              \"y = df['Species']  # Target variable ('Species' column)\\n\"\n",
      "              '\\n'\n",
      "              'X_train, X_test, y_train, y_test = train_test_split(X, y, '\n",
      "              'test_size=0.2, random_state=42)\\n'\n",
      "              '\\n'\n",
      "              '# Now, you can use X_train, X_test, y_train, and y_test for '\n",
      "              'training and testing your machine learning model.\\n'\n",
      "              'This code performs the following steps:Handles missing values '\n",
      "              'by filling them with the most common values in each respective '\n",
      "              'column.Encodes categorical labels with mappings provided.Splits '\n",
      "              'the dataset into training (80%) and testing (20%) sets using '\n",
      "              'train_test_split from scikit-learn, allowing you to use the '\n",
      "              'data for training and testing your machine learning model.',\n",
      "  'role': 'user',\n",
      "  'text': 'You will preprocess the data now\\n'\n",
      "          '1. Check for missing values and handle them by either dropping or '\n",
      "          'filling them with the most common values. Ensure that there is '\n",
      "          'enough data for training the model. You can only use %80 data for '\n",
      "          'training and %20 for testing\\n'\n",
      "          '2. Encode labels with mappings using the map function. Mapping '\n",
      "          'names: \\n'\n",
      "          \"   - sex_map = {'female': 1, 'male': 0}\\n\"\n",
      "          \"   - island_map = {'Biscoe': 1, 'Dream': 2, 'Torgensen': 3}\\n\"\n",
      "          \"   - diet_map = {'fish': 1, 'krill': 2, 'squid': 3, 'parental': 4}\\n\"\n",
      "          \"   - life_stage_map = {'chick': 1, 'juvenile': 2, 'adult': 3}\\n\"\n",
      "          \"   - health_metrics_map = {'healthy': 1, 'overweight': 2, \"\n",
      "          \"'underweight': 3}\\n\"\n",
      "          \"The dataset named 'df'.\"},\n",
      " {'response': \"Certainly, here's the code to shuffle the DataFrame, separate \"\n",
      "              \"it into feature matrix 'X' and target vector 'y', and split the \"\n",
      "              'data into training and test sets with random '\n",
      "              'shuffling:pythonCopy codeimport pandas as pd\\n'\n",
      "              'from sklearn.model_selection import train_test_split\\n'\n",
      "              '\\n'\n",
      "              '# Load the dataset into a Pandas DataFrame\\n'\n",
      "              \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "              'df = pd.read_csv(file_path)\\n'\n",
      "              '\\n'\n",
      "              '# 1. Shuffle the DataFrame\\n'\n",
      "              'df = df.sample(frac=1, random_state=42).reset_index(drop=True)  '\n",
      "              '# Shuffle with random_state for reproducibility\\n'\n",
      "              '\\n'\n",
      "              \"# 2. Separate the dataset into feature matrix 'X' and target \"\n",
      "              \"vector 'y'\\n\"\n",
      "              \"X = df.drop(columns=['Health Metrics'])  # Features (excluding \"\n",
      "              \"'Health Metrics' column)\\n\"\n",
      "              \"y = df['Health Metrics']  # Target variable ('Health Metrics' \"\n",
      "              'column)\\n'\n",
      "              '\\n'\n",
      "              '# 3. Split the data into training and test sets with 80% for '\n",
      "              'training and 20% for testing\\n'\n",
      "              'X_train, X_test, y_train, y_test = train_test_split(X, y, '\n",
      "              'test_size=0.2, random_state=42)\\n'\n",
      "              '\\n'\n",
      "              '# Now, you have shuffled data in X_train, X_test, y_train, and '\n",
      "              'y_test for training and testing your machine learning model.\\n'\n",
      "              'In this code:We shuffle the DataFrame using the sample method '\n",
      "              'with frac=1 to shuffle all rows. We also set a random_state for '\n",
      "              'reproducibility.We separate the dataset into the feature matrix '\n",
      "              \"'X', which includes all columns except 'Health Metrics', and \"\n",
      "              \"the target vector 'y', which contains only the 'Health Metrics' \"\n",
      "              'column.We split the shuffled data into training (80%) and test '\n",
      "              '(20%) sets using train_test_split from scikit-learn, ensuring '\n",
      "              'that the splitting is random with a specified random_state.',\n",
      "  'role': 'user',\n",
      "  'text': 'You already provide code for this but please recreate that part for '\n",
      "          'shuffling if needed. \\n'\n",
      "          \"1. Shuffle dataframe named 'df'.\\n\"\n",
      "          \"2. Separate the dataset into a feature matrix 'X' and a target \"\n",
      "          \"vector 'y'. The column 'health_metrics' is y, and all other columns \"\n",
      "          'should be included in X.\\n'\n",
      "          '3. Split the data into training and test sets with 80% of the data '\n",
      "          'for training and 20% for testing. \\n'\n",
      "          'Ensure that the splitting is random.'},\n",
      " {'response': 'To calculate and visualize the correlations of all features '\n",
      "              \"with the 'health_metrics' column in a Pandas DataFrame named \"\n",
      "              \"'df,' including the calculation of correlation coefficients and \"\n",
      "              'creating a heatmap for visualization, you can use the following '\n",
      "              'code:pythonCopy codeimport pandas as pd\\n'\n",
      "              'import seaborn as sns\\n'\n",
      "              'import matplotlib.pyplot as plt\\n'\n",
      "              '\\n'\n",
      "              '# Load the dataset into a Pandas DataFrame\\n'\n",
      "              \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "              'df = pd.read_csv(file_path)\\n'\n",
      "              '\\n'\n",
      "              '# Calculate correlation coefficients\\n'\n",
      "              'correlations = '\n",
      "              \"df.corr()['health_metrics'].drop('health_metrics')  # Remove \"\n",
      "              'self-correlation and select the target variable\\n'\n",
      "              '\\n'\n",
      "              '# Visualize the correlations in a heatmap\\n'\n",
      "              'plt.figure(figsize=(10, 6))\\n'\n",
      "              \"sns.heatmap(df.corr(), annot=True, cmap='coolwarm', \"\n",
      "              'fmt=\".2f\")\\n'\n",
      "              \"plt.title('Correlation Heatmap')\\n\"\n",
      "              'plt.show()\\n'\n",
      "              '\\n'\n",
      "              '# Interpretation of the heatmap:\\n'\n",
      "              '# - Correlation coefficients range from -1 to 1, where:\\n'\n",
      "              '#   - -1 indicates a perfect negative correlation (as one '\n",
      "              'variable goes up, the other goes down).\\n'\n",
      "              '#   - 1 indicates a perfect positive correlation (both '\n",
      "              'variables move in the same direction).\\n'\n",
      "              '#   - 0 indicates no correlation.\\n'\n",
      "              '# - In the heatmap, positive correlations are shown in warmer '\n",
      "              'colors (e.g., red), while negative correlations are shown in '\n",
      "              'cooler colors (e.g., blue).\\n'\n",
      "              '# - Strong correlations with the target variable '\n",
      "              \"('health_metrics') are indicated by values closer to -1 or 1, \"\n",
      "              'and these are the features that have the most influence on the '\n",
      "              'target.\\n'\n",
      "              '\\n'\n",
      "              '# To identify strong correlations with the target variable, you '\n",
      "              'can look for rows or columns in the heatmap with notably dark '\n",
      "              'or light colors (depending on the sign of the correlation).\\n'\n",
      "              'This code performs the following steps:Calculates the '\n",
      "              'correlation coefficients between all columns (features) and the '\n",
      "              \"'health_metrics' column using the corr() method. It then \"\n",
      "              'selects the correlations for all features except '\n",
      "              \"'health_metrics' itself.Creates a heatmap using Seaborn to \"\n",
      "              'visualize the correlations. In the heatmap, positive '\n",
      "              'correlations are represented by warmer colors (e.g., red), '\n",
      "              'while negative correlations are represented by cooler colors '\n",
      "              '(e.g., blue).The interpretation of the heatmap is provided in '\n",
      "              'the comments. Strong correlations with the target variable '\n",
      "              \"('health_metrics') are indicated by values closer to -1 or 1, \"\n",
      "              'which are represented by notably dark or light colors in the '\n",
      "              'heatmap.',\n",
      "  'role': 'user',\n",
      "  'text': 'Calculate and Visualize the correlations of all features in a '\n",
      "          \"Pandas DataFrame with 'health_metrics'. The DataFrame is named \"\n",
      "          \"'df'. Ensure the code includes:\\n\"\n",
      "          '1. Calculation of correlation coefficients.\\n'\n",
      "          '2. Visualization of these correlations in a heatmap.\\n'\n",
      "          'Also, instruct on how to interpret the heatmap to highlight any '\n",
      "          'strong correlations with the target variable. Note: Use lowercase '\n",
      "          \"and underscores for column names, e.g., 'health_metrics' instead of \"\n",
      "          \"'Health Metrics'.\"},\n",
      " {'response': 'The error message \"ValueError: could not convert string to '\n",
      "              'float: \\'Chinstrap\\'\" suggests that you are trying to calculate '\n",
      "              \"correlations between a string column ('Species' in this case) \"\n",
      "              \"and the 'health_metrics' column, which contains non-numeric \"\n",
      "              'values. To calculate correlations, you need to convert the '\n",
      "              \"categorical column ('Species') into a numeric format, such as \"\n",
      "              \"one-hot encoding or label encoding. Let's update the code to \"\n",
      "              \"handle this situation using label encoding for the 'Species' \"\n",
      "              'column:pythonCopy codeimport pandas as pd\\n'\n",
      "              'import seaborn as sns\\n'\n",
      "              'import matplotlib.pyplot as plt\\n'\n",
      "              'from sklearn.preprocessing import LabelEncoder\\n'\n",
      "              '\\n'\n",
      "              '# Load the dataset into a Pandas DataFrame\\n'\n",
      "              \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "              'df = pd.read_csv(file_path)\\n'\n",
      "              '\\n'\n",
      "              \"# 1. Label encode the 'Species' column\\n\"\n",
      "              'label_encoder = LabelEncoder()\\n'\n",
      "              \"df['Species_encoded'] = \"\n",
      "              \"label_encoder.fit_transform(df['Species'])\\n\"\n",
      "              '\\n'\n",
      "              '# 2. Calculate correlation coefficients\\n'\n",
      "              'correlations = '\n",
      "              \"df.corr()['health_metrics'].drop(['health_metrics', \"\n",
      "              \"'Species_encoded'])\\n\"\n",
      "              '\\n'\n",
      "              '# 3. Visualize the correlations in a heatmap\\n'\n",
      "              'plt.figure(figsize=(10, 6))\\n'\n",
      "              \"sns.heatmap(df.corr(), annot=True, cmap='coolwarm', \"\n",
      "              'fmt=\".2f\")\\n'\n",
      "              \"plt.title('Correlation Heatmap')\\n\"\n",
      "              'plt.show()\\n'\n",
      "              '\\n'\n",
      "              '# Interpretation of the heatmap remains the same as described '\n",
      "              'in the previous response.\\n'\n",
      "              'In this updated code:We use LabelEncoder from scikit-learn to '\n",
      "              \"convert the 'Species' column into a numeric format \"\n",
      "              \"('Species_encoded'). This allows us to calculate correlations \"\n",
      "              \"with 'health_metrics' since it's not possible to directly \"\n",
      "              'calculate correlations with string values.We calculate the '\n",
      "              \"correlation coefficients, excluding 'health_metrics' and \"\n",
      "              \"'Species_encoded', as they are not relevant for this purpose.We \"\n",
      "              'create the heatmap to visualize the correlations as previously '\n",
      "              'explained.Now, this code should work without raising the '\n",
      "              '\"ValueError\" and provide correlations with the '\n",
      "              \"'health_metrics' column.\",\n",
      "  'role': 'user',\n",
      "  'text': \"ValueError: could not convert string to float: 'Chinstrap'\\n\"\n",
      "          'please recreate the code based on this error'},\n",
      " {'response': 'To calculate the correlations of only numerical features with '\n",
      "              \"the target variable 'health_metrics' and avoid issues with \"\n",
      "              'non-numeric columns, you can modify the code as '\n",
      "              'follows:pythonCopy codeimport pandas as pd\\n'\n",
      "              'import seaborn as sns\\n'\n",
      "              'import matplotlib.pyplot as plt\\n'\n",
      "              '\\n'\n",
      "              '# Load the dataset into a Pandas DataFrame\\n'\n",
      "              \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "              'df = pd.read_csv(file_path)\\n'\n",
      "              '\\n'\n",
      "              '# Filter out only the numerical columns\\n'\n",
      "              \"numerical_columns = df.select_dtypes(include=['number'])\\n\"\n",
      "              '\\n'\n",
      "              '# Calculate correlation coefficients\\n'\n",
      "              'correlations = '\n",
      "              \"numerical_columns.corr()['health_metrics'].drop('health_metrics')\\n\"\n",
      "              '\\n'\n",
      "              '# Visualize the correlations in a heatmap\\n'\n",
      "              'plt.figure(figsize=(10, 6))\\n'\n",
      "              'sns.heatmap(correlations.to_frame(), annot=True, '\n",
      "              'cmap=\\'coolwarm\\', fmt=\".2f\")\\n'\n",
      "              \"plt.title('Correlation Heatmap')\\n\"\n",
      "              'plt.show()\\n'\n",
      "              '\\n'\n",
      "              '# Interpretation of the heatmap remains the same as described '\n",
      "              'in the previous response.\\n'\n",
      "              'In this modified code:We first filter out only the numerical '\n",
      "              \"columns using select_dtypes(include=['number']). This ensures \"\n",
      "              'that we are calculating correlations only with numerical '\n",
      "              'features.We calculate the correlation coefficients with the '\n",
      "              \"'health_metrics' column and drop the correlation with itself \"\n",
      "              '(which is always 1).We create the heatmap to visualize the '\n",
      "              'correlations using Seaborn as previously explained.The heatmap '\n",
      "              'will now display correlations only between numerical features '\n",
      "              \"and the 'health_metrics' target variable. You can interpret it \"\n",
      "              'as described in the previous response, looking for notably dark '\n",
      "              'or light colors to identify strong correlations with the target '\n",
      "              'variable.',\n",
      "  'role': 'user',\n",
      "  'text': 'Dataset includes both numerical and categorical columns. I need to '\n",
      "          'calculate the correlations of all numerical features with a target '\n",
      "          \"variable 'health_metrics'. However, I'm encountering a ValueError \"\n",
      "          'because of non-numeric columns. Modify the code for checking if the '\n",
      "          'value is a numerical one first After calculating the correlations, '\n",
      "          'also guide me on how to visualize these correlations in a heatmap '\n",
      "          'using seaborn or matplotlib. Please ensure that all column names '\n",
      "          'are in lowercase and use underscores instead of spaces.'},\n",
      " {'response': \"To encode the categorical target variable 'health_metrics' into \"\n",
      "              'a numerical form and calculate correlations with other '\n",
      "              \"features, you can follow these steps:Encode 'health_metrics' \"\n",
      "              'into numerical values.Calculate correlations between all '\n",
      "              'features (both numerical and encoded categorical) with the '\n",
      "              \"encoded 'health_metrics'.Visualize these correlations in a \"\n",
      "              \"heatmap using Seaborn or Matplotlib.Here's the Python code to \"\n",
      "              'achieve this:pythonCopy codeimport pandas as pd\\n'\n",
      "              'import seaborn as sns\\n'\n",
      "              'import matplotlib.pyplot as plt\\n'\n",
      "              '\\n'\n",
      "              '# Load the dataset into a Pandas DataFrame\\n'\n",
      "              \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "              'df = pd.read_csv(file_path)\\n'\n",
      "              '\\n'\n",
      "              \"# 1. Encode 'health_metrics' into numerical values\\n\"\n",
      "              \"health_metrics_map = {'healthy': 1, 'overweight': 2, \"\n",
      "              \"'underweight': 3}\\n\"\n",
      "              \"df['health_metrics_encoded'] = \"\n",
      "              \"df['health_metrics'].map(health_metrics_map)\\n\"\n",
      "              '\\n'\n",
      "              '# 2. Calculate correlations with all features, including the '\n",
      "              'encoded target\\n'\n",
      "              'correlations = '\n",
      "              \"df.corr()['health_metrics_encoded'].drop(['health_metrics_encoded', \"\n",
      "              \"'health_metrics'])\\n\"\n",
      "              '\\n'\n",
      "              '# 3. Visualize the correlations in a heatmap\\n'\n",
      "              'plt.figure(figsize=(10, 6))\\n'\n",
      "              'sns.heatmap(correlations.to_frame(), annot=True, '\n",
      "              'cmap=\\'coolwarm\\', fmt=\".2f\")\\n'\n",
      "              \"plt.title('Correlation Heatmap')\\n\"\n",
      "              'plt.show()\\n'\n",
      "              '\\n'\n",
      "              '# Interpretation of the heatmap:\\n'\n",
      "              '# - Darker colors indicate stronger correlations, whether '\n",
      "              \"positive or negative, with the encoded 'health_metrics'.\\n\"\n",
      "              '# - Positive correlations are represented by values closer to '\n",
      "              '1, while negative correlations are closer to -1.\\n'\n",
      "              \"In this code:We encode the categorical 'health_metrics' column \"\n",
      "              'into numerical values using the provided health_metrics_map. '\n",
      "              'The encoded values are stored in a new column named '\n",
      "              \"'health_metrics_encoded.'We calculate the correlations between \"\n",
      "              \"all features (both numerical and the encoded 'health_metrics') \"\n",
      "              \"with the encoded 'health_metrics_encoded' column.We create a \"\n",
      "              'heatmap to visualize these correlations. Darker colors indicate '\n",
      "              'stronger correlations, and you can interpret them as described '\n",
      "              'in the comments.This code will help you visualize the '\n",
      "              'correlations between all features and the encoded '\n",
      "              \"'health_metrics' target variable.\",\n",
      "  'role': 'user',\n",
      "  'text': \"I have a dataset in a Pandas DataFrame named 'df' with both \"\n",
      "          'numerical and categorical columns. The target variable '\n",
      "          \"'health_metrics' is categorical with values like 'overweight', \"\n",
      "          \"'underweight', etc. I need to encode this target variable \"\n",
      "          'numerically and then calculate the correlations of all features '\n",
      "          'with this encoded target. Please guide me on how to encode '\n",
      "          \"'health_metrics' into a numerical form and then compute \"\n",
      "          'correlations with other features. Additionally, provide '\n",
      "          'instructions on visualizing these correlations in a heatmap. '\n",
      "          'Remember to use lowercase and underscores for column names.'},\n",
      " {'response': 'To calculate correlations only between numerical features and '\n",
      "              \"the encoded 'health_metrics' column while excluding other \"\n",
      "              \"categorical columns like 'species,' you can follow these \"\n",
      "              \"steps:Encode the 'health_metrics' column into numerical \"\n",
      "              'values.Select only the numerical columns for correlation '\n",
      "              'calculation.Calculate the correlations.Visualize these '\n",
      "              \"correlations in a heatmap using Seaborn or Matplotlib.Here's a \"\n",
      "              'Python code snippet that accomplishes this:pythonCopy '\n",
      "              'codeimport pandas as pd\\n'\n",
      "              'import seaborn as sns\\n'\n",
      "              'import matplotlib.pyplot as plt\\n'\n",
      "              '\\n'\n",
      "              '# Load the dataset into a Pandas DataFrame\\n'\n",
      "              \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "              'df = pd.read_csv(file_path)\\n'\n",
      "              '\\n'\n",
      "              \"# 1. Encode 'health_metrics' into numerical values\\n\"\n",
      "              \"health_metrics_map = {'healthy': 1, 'overweight': 2, \"\n",
      "              \"'underweight': 3}\\n\"\n",
      "              \"df['health_metrics_encoded'] = \"\n",
      "              \"df['health_metrics'].map(health_metrics_map)\\n\"\n",
      "              '\\n'\n",
      "              '# 2. Select only the numerical columns for correlation '\n",
      "              'calculation\\n'\n",
      "              \"numerical_columns = df.select_dtypes(include=['number'])\\n\"\n",
      "              '\\n'\n",
      "              '# 3. Calculate correlations\\n'\n",
      "              'correlations = '\n",
      "              \"numerical_columns.corrwith(df['health_metrics_encoded']).sort_values(ascending=False)\\n\"\n",
      "              '\\n'\n",
      "              '# 4. Visualize the correlations in a heatmap\\n'\n",
      "              'plt.figure(figsize=(10, 6))\\n'\n",
      "              'sns.heatmap(correlations.to_frame(), annot=True, '\n",
      "              'cmap=\\'coolwarm\\', fmt=\".2f\")\\n'\n",
      "              \"plt.title('Correlations with Encoded health_metrics')\\n\"\n",
      "              'plt.show()\\n'\n",
      "              '\\n'\n",
      "              '# Interpretation of the heatmap:\\n'\n",
      "              '# - Darker colors indicate stronger positive or negative '\n",
      "              'correlations between numerical features and the encoded '\n",
      "              \"'health_metrics'.\\n\"\n",
      "              '# - Positive correlations are represented by values closer to '\n",
      "              '1, while negative correlations are closer to -1.\\n'\n",
      "              \"In this code:We encode the categorical 'health_metrics' column \"\n",
      "              'into numerical values, as you did before.We select only the '\n",
      "              \"numerical columns using select_dtypes(include=['number']), \"\n",
      "              'ensuring that we are including only numerical features for '\n",
      "              'correlation calculation.We calculate the correlations between '\n",
      "              'the selected numerical columns and the encoded '\n",
      "              \"'health_metrics_encoded' column using corrwith.We create a \"\n",
      "              'heatmap to visualize these correlations, where darker colors '\n",
      "              'indicate stronger correlations, and you can interpret them as '\n",
      "              'described in the comments.This code should correctly calculate '\n",
      "              'and visualize the correlations between numerical features and '\n",
      "              \"the encoded 'health_metrics' column while excluding other \"\n",
      "              \"categorical columns like 'species.'\",\n",
      "  'role': 'user',\n",
      "  'text': \"I've encoded the categorical target variable 'health_metrics' into \"\n",
      "          \"a numerical format. However, I'm facing a ValueError: could not \"\n",
      "          'convert string to float when trying to calculate feature '\n",
      "          'correlations. How can I modify my code to calculate correlations '\n",
      "          \"only between numerical features and the encoded 'health_metrics' \"\n",
      "          \"column, excluding any other categorical columns like 'species'? \"\n",
      "          'Please provide a Python code snippet that correctly computes these '\n",
      "          'correlations and a way to visualize them in a heatmap.'},\n",
      " {'response': 'To select a subset of features that are likely strong '\n",
      "              'predictors for the target variable based on correlation '\n",
      "              'analysis, you can follow these steps:Identify the features with '\n",
      "              'the highest positive and negative correlation values with the '\n",
      "              'target variable.Choose a threshold for correlation strength '\n",
      "              'that determines which features to select.Justify your selection '\n",
      "              \"based on the correlation values and domain knowledge.Here's a \"\n",
      "              'Python code example that demonstrates how to select features '\n",
      "              'based on correlation strengths:pythonCopy codeimport pandas as '\n",
      "              'pd\\n'\n",
      "              '\\n'\n",
      "              '# Load the dataset into a Pandas DataFrame\\n'\n",
      "              \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "              'df = pd.read_csv(file_path)\\n'\n",
      "              '\\n'\n",
      "              \"# Encode the 'health_metrics' column into numerical values\\n\"\n",
      "              \"health_metrics_map = {'healthy': 1, 'overweight': 2, \"\n",
      "              \"'underweight': 3}\\n\"\n",
      "              \"df['health_metrics_encoded'] = \"\n",
      "              \"df['health_metrics'].map(health_metrics_map)\\n\"\n",
      "              '\\n'\n",
      "              '# Calculate correlations between numerical features and the '\n",
      "              \"encoded 'health_metrics'\\n\"\n",
      "              'correlations = '\n",
      "              \"df.corrwith(df['health_metrics_encoded']).sort_values(ascending=False)\\n\"\n",
      "              '\\n'\n",
      "              '# Set a threshold for selecting strong predictors\\n'\n",
      "              'correlation_threshold = 0.2  # You can adjust this threshold '\n",
      "              'based on your requirements\\n'\n",
      "              '\\n'\n",
      "              '# Select features with correlations above the threshold '\n",
      "              '(positive and negative)\\n'\n",
      "              'selected_features = correlations[(correlations > '\n",
      "              'correlation_threshold) | (correlations < '\n",
      "              '-correlation_threshold)]\\n'\n",
      "              '\\n'\n",
      "              '# Display the selected features and their correlation values\\n'\n",
      "              'print(\"Selected Features:\")\\n'\n",
      "              'print(selected_features)\\n'\n",
      "              '\\n'\n",
      "              '# Interpretation and justification:\\n'\n",
      "              '# - Features with positive correlations indicate that as the '\n",
      "              \"feature increases, the likelihood of 'health_metrics' being \"\n",
      "              \"'overweight' or 'underweight' also increases.\\n\"\n",
      "              '# - Features with negative correlations indicate the opposite, '\n",
      "              \"as the feature decreases, the likelihood of 'health_metrics' \"\n",
      "              \"being 'overweight' or 'underweight' increases.\\n\"\n",
      "              '# - By setting a threshold (e.g., 0.2), you can choose features '\n",
      "              \"that have a relatively strong impact on 'health_metrics'.\\n\"\n",
      "              '# - The threshold can be adjusted based on your domain '\n",
      "              'knowledge and the specific requirements of your predictive '\n",
      "              'model.\\n'\n",
      "              '\\n'\n",
      "              '# You can further analyze these selected features and perform '\n",
      "              'machine learning modeling with them.\\n'\n",
      "              'In this code:We calculate the correlations between numerical '\n",
      "              \"features and the encoded 'health_metrics' column.We set a \"\n",
      "              'threshold (correlation_threshold) to determine which features '\n",
      "              'are considered strong predictors. You can adjust this threshold '\n",
      "              'based on your domain knowledge and requirements. Features with '\n",
      "              'correlations above or below this threshold (positive or '\n",
      "              'negative) are selected.We display the selected features and '\n",
      "              'their correlation values, providing an initial list of '\n",
      "              \"potential predictors for the 'health_metrics' target \"\n",
      "              'variable.Remember that correlation does not imply causation, '\n",
      "              'and the selected features should be further analyzed and '\n",
      "              'validated in the context of your specific prediction or '\n",
      "              'classification problem. Domain knowledge and domain-specific '\n",
      "              'expertise are crucial for making informed decisions about '\n",
      "              'feature selection.',\n",
      "  'role': 'user',\n",
      "  'text': 'With computed correlations between features and an encoded target '\n",
      "          'variable, guide me on how to select a subset of features that are '\n",
      "          'likely strong predictors for the target. Explain how to interpret '\n",
      "          'the correlation values to identify these features and provide a '\n",
      "          'Python code example for selecting them based on their correlation '\n",
      "          'strengths. Emphasize the justification for choosing these features '\n",
      "          'based on the correlation analysis.'},\n",
      " {'response': 'Certainly! Here are two hypothetical features that could '\n",
      "              'enhance predictive accuracy for the target variable '\n",
      "              \"'health_metrics' based on the existing data and their expected \"\n",
      "              \"impact on the model's accuracy:Daily Caloric Intake (New \"\n",
      "              'Feature 1):Derivation: Calculate the daily caloric intake of '\n",
      "              'each penguin based on their diet and body mass. You can '\n",
      "              'estimate the caloric intake required for different diets (e.g., '\n",
      "              'fish, krill, squid, parental) and then calculate the daily '\n",
      "              'caloric intake by multiplying the estimated value by the '\n",
      "              \"penguin's body mass (in grams).Expected Impact: Penguins with \"\n",
      "              'insufficient daily caloric intake compared to their dietary '\n",
      "              'requirements may have a higher likelihood of being '\n",
      "              \"'underweight.' Conversely, those with excessive caloric intake \"\n",
      "              \"may have a higher likelihood of being 'overweight.' This \"\n",
      "              'feature could provide valuable information to the model about '\n",
      "              \"the penguin's nutrition and health status.Seasonality Indicator \"\n",
      "              '(New Feature 2):Derivation: Determine the seasonality of data '\n",
      "              \"collection by examining the 'Year' column. You can categorize \"\n",
      "              'the years into different seasons (e.g., summer, winter) based '\n",
      "              \"on the hemisphere's calendar and location of the penguins' \"\n",
      "              'habitat.Expected Impact: Seasonal changes may influence the '\n",
      "              'availability of food and, consequently, the health of penguins. '\n",
      "              'For example, during certain seasons, food sources may be more '\n",
      "              'abundant, leading to better health. This feature can help the '\n",
      "              'model account for seasonality-related variations in '\n",
      "              \"'health_metrics.'Here's a hypothetical Python code snippet to \"\n",
      "              'calculate and visualize the correlations of these new features '\n",
      "              \"with the encoded 'health_metrics' target variable:pythonCopy \"\n",
      "              'codeimport pandas as pd\\n'\n",
      "              'import seaborn as sns\\n'\n",
      "              'import matplotlib.pyplot as plt\\n'\n",
      "              '\\n'\n",
      "              '# Load the dataset into a Pandas DataFrame\\n'\n",
      "              \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "              'df = pd.read_csv(file_path)\\n'\n",
      "              '\\n'\n",
      "              \"# Encode the 'health_metrics' column into numerical values\\n\"\n",
      "              \"health_metrics_map = {'healthy': 1, 'overweight': 2, \"\n",
      "              \"'underweight': 3}\\n\"\n",
      "              \"df['health_metrics_encoded'] = \"\n",
      "              \"df['health_metrics'].map(health_metrics_map)\\n\"\n",
      "              '\\n'\n",
      "              '# Hypothetical Feature 1: Daily Caloric Intake\\n'\n",
      "              '# Calculate daily caloric intake (hypothetical calculation)\\n'\n",
      "              \"caloric_intake = df['Diet'].map({'fish': 500, 'krill': 300, \"\n",
      "              \"'squid': 400, 'parental': 600}) * df['Body Mass (g)']\\n\"\n",
      "              '\\n'\n",
      "              '# Hypothetical Feature 2: Seasonality Indicator\\n'\n",
      "              '# Categorize years into seasons (hypothetical categorization)\\n'\n",
      "              \"seasonality = df['Year'].map({2017: 'Winter', 2018: 'Spring', \"\n",
      "              \"2019: 'Summer', 2020: 'Autumn'})\\n\"\n",
      "              '\\n'\n",
      "              '# Calculate correlations with the new features\\n'\n",
      "              'correlation_caloric_intake = '\n",
      "              \"df['health_metrics_encoded'].corr(caloric_intake)\\n\"\n",
      "              'correlation_seasonality = '\n",
      "              \"df['health_metrics_encoded'].corr(seasonality)\\n\"\n",
      "              '\\n'\n",
      "              '# Visualize the correlations\\n'\n",
      "              'plt.figure(figsize=(10, 6))\\n'\n",
      "              \"sns.barplot(x=['Daily Caloric Intake', 'Seasonality'], \"\n",
      "              'y=[correlation_caloric_intake, correlation_seasonality])\\n'\n",
      "              \"plt.title('Correlations of New Features with Encoded \"\n",
      "              \"health_metrics')\\n\"\n",
      "              \"plt.ylabel('Correlation Coefficient')\\n\"\n",
      "              'plt.ylim(-1, 1)\\n'\n",
      "              'plt.show()\\n'\n",
      "              '\\n'\n",
      "              '# Interpretation:\\n'\n",
      "              '# - Positive correlations indicate that the feature is '\n",
      "              \"positively related to 'health_metrics.'\\n\"\n",
      "              '# - Negative correlations indicate a negative relationship.\\n'\n",
      "              '# - The higher the absolute correlation coefficient, the '\n",
      "              \"stronger the feature's influence on 'health_metrics.'\\n\"\n",
      "              'In this code, we calculate the correlations of the hypothetical '\n",
      "              \"new features ('Daily Caloric Intake' and 'Seasonality \"\n",
      "              \"Indicator') with the encoded 'health_metrics' target variable \"\n",
      "              'and visualize them using a bar plot. Positive correlations '\n",
      "              \"suggest a positive relationship with 'health_metrics,' while \"\n",
      "              'negative correlations suggest a negative relationship. The '\n",
      "              'magnitude of the correlation coefficient indicates the strength '\n",
      "              'of the relationship.',\n",
      "  'role': 'user',\n",
      "  'text': 'I need to propose two hypothetical features that could enhance the '\n",
      "          \"predictive accuracy for the target variable 'health_metrics'. Can \"\n",
      "          'you suggest two potential new features, explaining how they might '\n",
      "          'be derived from the existing data or external sources, and their '\n",
      "          \"expected impact on the model's accuracy? Also, provide a \"\n",
      "          'hypothetical example of how to calculate and show the correlations '\n",
      "          'of these new features with the target variable using Python. Note '\n",
      "          \"that the target variable 'health_metrics' is categorical and has \"\n",
      "          'been numerically encoded.\"'},\n",
      " {'response': \"If you encountered a KeyError for the column 'Diet,' it \"\n",
      "              \"suggests that the column 'Diet' does not exist in your \"\n",
      "              'DataFrame. To identify and correct the issue, you can follow '\n",
      "              'these steps:Check the column names: Verify that the column name '\n",
      "              \"'Diet' exists in your DataFrame. It's possible that the column \"\n",
      "              'name is different from what you expected. You can print the '\n",
      "              'list of column names to confirm.Handle missing columns: If the '\n",
      "              \"'Diet' column is missing, you can consider the following \"\n",
      "              'options:Check for typos: Ensure that you have spelled the '\n",
      "              'column name correctly. Column names are case-sensitive.Confirm '\n",
      "              'dataset structure: Review the dataset or its documentation to '\n",
      "              \"make sure that the 'Diet' column is supposed to be \"\n",
      "              'present.Update column name: If the column name is different, '\n",
      "              \"you can access it using the correct name.Here's how you can \"\n",
      "              'check the column names and handle the situation if the column '\n",
      "              \"name is different or if the column doesn't exist:pythonCopy \"\n",
      "              'codeimport pandas as pd\\n'\n",
      "              '\\n'\n",
      "              '# Load the dataset into a Pandas DataFrame\\n'\n",
      "              \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "              'df = pd.read_csv(file_path)\\n'\n",
      "              '\\n'\n",
      "              '# 1. Check the column names\\n'\n",
      "              'print(\"Column names in the DataFrame:\")\\n'\n",
      "              'print(df.columns)\\n'\n",
      "              '\\n'\n",
      "              '# 2. Handle missing columns\\n'\n",
      "              \"if 'Diet' not in df.columns:\\n\"\n",
      "              \"    # If 'Diet' is not found, you can handle it based on your \"\n",
      "              'needs.\\n'\n",
      "              '    # For example, you can access a different column with a '\n",
      "              'similar purpose if available, or perform other data handling '\n",
      "              'tasks.\\n'\n",
      "              '    print(\"The \\'Diet\\' column is missing. Please check the '\n",
      "              'dataset structure or handle this situation accordingly.\")\\n'\n",
      "              'else:\\n'\n",
      "              \"    # If 'Diet' exists, you can access it as df['Diet'].\\n\"\n",
      "              \"    diet_column = df['Diet']\\n\"\n",
      "              \"    # Now, you can use the 'diet_column' for your \"\n",
      "              'calculations.\\n'\n",
      "              '    print(\"The \\'Diet\\' column exists, and you can access '\n",
      "              'it.\")\\n'\n",
      "              \"By following these steps, you can identify whether the 'Diet' \"\n",
      "              'column is present in your DataFrame, handle situations where '\n",
      "              'the column name is different, or take appropriate actions if '\n",
      "              \"the column doesn't exist.\",\n",
      "  'role': 'user',\n",
      "  'text': \"Encountered a KeyError for the column 'Diet'. How can I identify \"\n",
      "          'and correct the issue causing this error? Please guide me on how to '\n",
      "          'solve If the column name is different, provide guidance on how to '\n",
      "          'access it correctly in Python. Additionally, if the column does not '\n",
      "          'exist, suggest ways to handle this situation.\"'},\n",
      " {'response': 'I apologize for the oversight in using capital letters for '\n",
      "              \"column names. To resolve the correlation issues, let's make \"\n",
      "              'sure we are using the correct column names and address any '\n",
      "              \"issues with the calculations. Here's the updated \"\n",
      "              'code:pythonCopy codeimport pandas as pd\\n'\n",
      "              'import seaborn as sns\\n'\n",
      "              'import matplotlib.pyplot as plt\\n'\n",
      "              '\\n'\n",
      "              '# Load the dataset into a Pandas DataFrame\\n'\n",
      "              \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "              'df = pd.read_csv(file_path)\\n'\n",
      "              '\\n'\n",
      "              \"# Encode the 'health_metrics' column into numerical values\\n\"\n",
      "              \"health_metrics_map = {'healthy': 1, 'overweight': 2, \"\n",
      "              \"'underweight': 3}\\n\"\n",
      "              \"df['health_metrics_encoded'] = df['Health \"\n",
      "              \"Metrics'].map(health_metrics_map)\\n\"\n",
      "              '\\n'\n",
      "              '# Hypothetical Feature 1: Daily Caloric Intake\\n'\n",
      "              '# Calculate daily caloric intake (hypothetical calculation)\\n'\n",
      "              \"diet_caloric_map = {'fish': 500, 'krill': 300, 'squid': 400, \"\n",
      "              \"'parental': 600}\\n\"\n",
      "              \"df['Daily Caloric Intake'] = df['Diet'].map(diet_caloric_map) * \"\n",
      "              \"df['Body Mass (g)']\\n\"\n",
      "              '\\n'\n",
      "              '# Hypothetical Feature 2: Seasonality Indicator\\n'\n",
      "              '# Categorize years into seasons (hypothetical categorization)\\n'\n",
      "              \"seasonality_map = {2007: 'Winter', 2008: 'Spring', 2009: \"\n",
      "              \"'Summer', 2010: 'Autumn'}\\n\"\n",
      "              \"df['Seasonality'] = df['Year'].map(seasonality_map)\\n\"\n",
      "              '\\n'\n",
      "              '# Calculate correlations with the new features\\n'\n",
      "              'correlation_caloric_intake = '\n",
      "              \"df['health_metrics_encoded'].corr(df['Daily Caloric Intake'])\\n\"\n",
      "              'correlation_seasonality = '\n",
      "              \"df['health_metrics_encoded'].corr(df['Seasonality'])\\n\"\n",
      "              '\\n'\n",
      "              '# Visualize the correlations\\n'\n",
      "              'plt.figure(figsize=(10, 6))\\n'\n",
      "              \"sns.barplot(x=['Daily Caloric Intake', 'Seasonality'], \"\n",
      "              'y=[correlation_caloric_intake, correlation_seasonality])\\n'\n",
      "              \"plt.title('Correlations of New Features with Encoded Health \"\n",
      "              \"Metrics')\\n\"\n",
      "              \"plt.ylabel('Correlation Coefficient')\\n\"\n",
      "              'plt.ylim(-1, 1)\\n'\n",
      "              'plt.show()\\n'\n",
      "              '\\n'\n",
      "              '# Interpretation:\\n'\n",
      "              \"# - A correlation of 0 for 'Daily Caloric Intake' suggests no \"\n",
      "              \"linear relationship with 'Health Metrics.'\\n\"\n",
      "              \"# - No line for 'Seasonality' indicates no linear relationship \"\n",
      "              'as well.\\n'\n",
      "              'In this updated code:We corrected the column names to use '\n",
      "              'lowercase and underscores.We addressed the issues with '\n",
      "              \"correlation coefficients. If the correlations for 'Daily \"\n",
      "              \"Caloric Intake' and 'Seasonality' are 0 or close to 0, it \"\n",
      "              'suggests that there may not be a strong linear relationship '\n",
      "              \"between these features and the encoded 'Health Metrics.' In \"\n",
      "              \"such cases, it's essential to explore other feature engineering \"\n",
      "              'or selection techniques to improve model accuracy.',\n",
      "  'role': 'user',\n",
      "  'text': 'i find out the error is because you used capital letters on column '\n",
      "          'names dont do it again. Also daily calorie intake  correlecian '\n",
      "          'coefficient is 0 (straight line) and seasonality is no line at all '\n",
      "          'please solve these issues'},\n",
      " {'response': 'To use GridSearchCV in scikit-learn to tune hyperparameters of '\n",
      "              'a DecisionTreeClassifier, you can follow these steps:Import '\n",
      "              'necessary libraries.Define the parameter grid with the '\n",
      "              'hyperparameters you want to tune.Create a '\n",
      "              'DecisionTreeClassifier.Create a GridSearchCV instance with the '\n",
      "              'classifier and parameter grid.Fit the GridSearchCV object to '\n",
      "              'your data and target variable.Retrieve and analyze the best '\n",
      "              \"hyperparameters.Here's a Python code example with explanations \"\n",
      "              'for each step:pythonCopy codeimport pandas as pd\\n'\n",
      "              'from sklearn.model_selection import GridSearchCV, '\n",
      "              'train_test_split\\n'\n",
      "              'from sklearn.tree import DecisionTreeClassifier\\n'\n",
      "              '\\n'\n",
      "              '# Load the dataset into a Pandas DataFrame\\n'\n",
      "              \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "              'df = pd.read_csv(file_path)\\n'\n",
      "              '\\n'\n",
      "              '# Split the data into features (X) and target variable (y)\\n'\n",
      "              \"X = df.drop(columns=['Health Metrics'])  # Features (excluding \"\n",
      "              'target variable)\\n'\n",
      "              \"y = df['Health Metrics']  # Target variable\\n\"\n",
      "              '\\n'\n",
      "              '# Define the parameter grid for tuning\\n'\n",
      "              'param_grid = {\\n'\n",
      "              \"    'max_depth': [None, 10, 20, 30],  # Maximum depth of the \"\n",
      "              'tree (None for unlimited depth)\\n'\n",
      "              \"    'min_samples_split': [2, 5, 10],  # Minimum number of \"\n",
      "              'samples required to split an internal node\\n'\n",
      "              '}\\n'\n",
      "              '\\n'\n",
      "              '# Create a DecisionTreeClassifier\\n'\n",
      "              'clf = DecisionTreeClassifier(random_state=42)\\n'\n",
      "              '\\n'\n",
      "              '# Create a GridSearchCV instance with cross-validation value of '\n",
      "              '5\\n'\n",
      "              'grid_search = GridSearchCV(estimator=clf, '\n",
      "              \"param_grid=param_grid, cv=5, scoring='accuracy')\\n\"\n",
      "              '\\n'\n",
      "              '# Fit the GridSearchCV object to the data\\n'\n",
      "              'grid_search.fit(X, y)\\n'\n",
      "              '\\n'\n",
      "              '# Retrieve the best hyperparameters\\n'\n",
      "              \"best_max_depth = grid_search.best_params_['max_depth']\\n\"\n",
      "              'best_min_samples_split = '\n",
      "              \"grid_search.best_params_['min_samples_split']\\n\"\n",
      "              'best_accuracy = grid_search.best_score_\\n'\n",
      "              '\\n'\n",
      "              'print(f\"Best Hyperparameters: Max Depth = {best_max_depth}, Min '\n",
      "              'Samples Split = {best_min_samples_split}\")\\n'\n",
      "              'print(f\"Best Cross-Validation Accuracy: {best_accuracy:.2f}\")\\n'\n",
      "              'In this code:We load the dataset into a Pandas DataFrame and '\n",
      "              'split it into features (X) and the target variable (y).We '\n",
      "              'define the parameter grid (param_grid) with the hyperparameters '\n",
      "              \"you want to tune: 'max_depth' and 'min_samples_split'. You can \"\n",
      "              'add more hyperparameters to the grid if needed.We create a '\n",
      "              'DecisionTreeClassifier (clf) with a fixed random state for '\n",
      "              'reproducibility.We create a GridSearchCV instance (grid_search) '\n",
      "              'with the DecisionTreeClassifier, the parameter grid, 5-fold '\n",
      "              'cross-validation (cv=5), and scoring based on accuracy '\n",
      "              \"(scoring='accuracy').We fit the GridSearchCV object to the \"\n",
      "              'data, which performs a search over the specified '\n",
      "              'hyperparameters and cross-validates to find the best '\n",
      "              'combination.We retrieve and print the best hyperparameters '\n",
      "              '(best_max_depth and best_min_samples_split) and the best '\n",
      "              'cross-validation accuracy (best_accuracy).By running this code, '\n",
      "              'you will find the best hyperparameters for your '\n",
      "              'DecisionTreeClassifier and their corresponding cross-validation '\n",
      "              'accuracy score. These hyperparameters can be used to build a '\n",
      "              'more optimized model for your classification task.',\n",
      "  'role': 'user',\n",
      "  'text': 'Provide guidance on using GridSearchCV in scikit-learn to tune '\n",
      "          'hyperparameters of a DecisionTreeClassifier. I want to choose two '\n",
      "          'hyperparameters to tune based on the Scikit-learn decision tree '\n",
      "          'documentation. Explain how to set up GridSearchCV with a '\n",
      "          'cross-validation value of 5 and use validation accuracy to '\n",
      "          'determine the best hyperparameters. The dataset is in a DataFrame '\n",
      "          \"named 'df' and the target variable is 'health_metrics'.\"}]\n",
      "                                     code  code_responses\n",
      "0    0031c86e-81f4-4eef-9e0e-28037abf9883              14\n",
      "1    0225686d-b825-4cac-8691-3a3a5343df2b              17\n",
      "2    041f950b-c013-409a-a642-cffff60b9d4b               7\n",
      "3    04f91058-d0f8-4324-83b2-19c671f433dc              19\n",
      "4    089eb66d-4c3a-4f58-b98f-a3774a2efb34              82\n",
      "..                                    ...             ...\n",
      "122  f24219d6-07f0-4baf-80ac-18475dc5b66f              16\n",
      "123  f2f18684-4a16-4c05-a2d1-c0f96d1de869              59\n",
      "124  f852596d-fdca-45aa-9050-d4f76ce6a53c              25\n",
      "125  f8ec3336-fd48-4654-ad98-62ccfb96d096              14\n",
      "126  fb8de815-224c-4d06-9fd4-7156d1a9920d              30\n",
      "\n",
      "[127 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "pprint(code2convos[\"0031c86e-81f4-4eef-9e0e-28037abf9883\"])\n",
    "pprint(total_code_response_df)\n",
    "# Check for the presence of a code block\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Things to do:\n",
    "- Prompt matching with questions\n",
    "- Feature Engineering\n",
    "- Question Grades preparation\n",
    "- Train/Test split\n",
    "- Fitting a model for predicting the scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Matching\n",
    "> We want to match the prompts with the questions in the Homework Let's\n",
    "> do it with a simple term frequency vectorizing method. For each prompt,\n",
    "> we will come with a vector that represents it. We will do the same\n",
    "> thing with each of the homework questions. Then, we will calculate the\n",
    "> vectors distanance to do the matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "responses = []\n",
    "code2prompts = defaultdict(list)\n",
    "for code , convos in code2convos.items():\n",
    "    user_prompts = []\n",
    "    for conv in convos:\n",
    "        if conv[\"role\"] == \"user\":\n",
    "            prompts.append(conv[\"text\"])\n",
    "            responses.append(conv[\"response\"])\n",
    "            user_prompts.append(conv[\"text\"])\n",
    "    code2prompts[code] = user_prompts      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Load a CSV file into a Pandas in Python. The file is named 'cs412_hw1_dataset.csv' and contains columns like 'Species', 'Island', 'Sex', 'Diet', 'Year', 'Life Stage', 'Body Mass (g)', 'Bill Length (mm)', 'Bill Depth (mm)', 'Flipper Length (mm)', and 'Health Metrics'.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"\"\"Load training dataset (5 pts)\n",
    "    *  Read the .csv file with the pandas library\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Understanding the dataset & Preprocessing (15 pts)\n",
    "Understanding the Dataset: (5 pts)\n",
    "> - Find the shape of the dataset (number of samples & number of attributes). (Hint: You can use the **shape** function)\n",
    "> - Display variable names (both dependent and independent).\n",
    "> - Display the summary of the dataset. (Hint: You can use the **info** function)\n",
    "> - Display the first 5 rows from training dataset. (Hint: You can use the **head** function)\n",
    "Preprocessing: (10 pts)\n",
    "\n",
    "> - Check if there are any missing values in the dataset. If there are, you can either drop these values or fill it with most common values in corresponding rows. **Be careful that you have enough data for training the  model.**\n",
    "\n",
    "> - Encode categorical labels with the mappings given in the cell below. (Hint: You can use **map** function)\n",
    "\"\"\",\n",
    "\"\"\"Set X & y, split data (5 pts)\n",
    "\n",
    "*   Shuffle the dataset.\n",
    "*   Seperate your dependent variable X, and your independent variable y. The column health_metrics is y, the rest is X.\n",
    "*   Split training and test sets as 80% and 20%, respectively.\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Features and Correlations (10 pts)\n",
    "\n",
    "* Correlations of features with health (4 points)\n",
    "Calculate the correlations for all features in dataset. Highlight any strong correlations with the target variable. Plot your results in a heatmap.\n",
    "\n",
    "* Feature Selection (3 points)\n",
    "Select a subset of features that are likely strong predictors, justifying your choices based on the computed correlations.\n",
    "\n",
    "* Hypothetical Driver Features (3 points)\n",
    "Propose two hypothetical features that could enhance the model's predictive accuracy for Y, explaining how they might be derived and their expected impact. Show the resulting correlations with target variable.\n",
    "\n",
    "* __Note:__ You get can get help from GPT.\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Tune Hyperparameters (20 pts)\n",
    "* Choose 2 hyperparameters to tune. You can use the Scikit learn decision tree documentation for the available hyperparameters *(Hyperparameters are listed under \"Parameters\" in the documentation)*. Use GridSearchCV for hyperparameter tuning, with a cross-validation value of 5. Use validation accuracy to pick the best hyper-parameter values. (15 pts)\n",
    "-Explain the hyperparameters you chose to tune. *(What are the hyperparameters you chose? Why did you choose them?)* (5 pts)\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Re-train and plot the decision tree with the hyperparameters you have chosen (15 pts)\n",
    "- Re-train model with the hyperparameters you have chosen in part 5). (10 pts)\n",
    "- Plot the tree you have trained. (5 pts)\n",
    "Hint: You can import the **plot_tree** function from the sklearn library.\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Test your classifier on the test set (20 pts)\n",
    "- Predict the labels of testing data using the tree you have trained in step 6. (10 pts)\n",
    "- Report the classification accuracy. (2 pts)\n",
    "- Plot & investigate the confusion matrix. Fill the following blanks. (8 pts)\n",
    "> The model most frequently mistakes class(es) _________ for class(es) _________.\n",
    "Hint: You can use the confusion_matrix function from sklearn.metrics\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Find the information gain on the first split (10 pts)\"\"\",\n",
    "#####################\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "# Original stop words from scikit-learn\n",
    "original_stop_words = text.ENGLISH_STOP_WORDS\n",
    "\n",
    "\n",
    "# Combine original and additional stop words into a list\n",
    "combined_stop_words = list(original_stop_words)\n",
    "\n",
    "# Token pattern that matches words with English letters only (no numbers)\n",
    "# This pattern will match words that consist of two or more English letters\n",
    "token_pattern = r'(?u)\\b[A-Za-z]{2,}\\b'\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,                  # Convert all characters to lowercase\n",
    "    stop_words=combined_stop_words,  # Combined stop words\n",
    "    token_pattern=token_pattern,     # Custom token pattern for English letters only\n",
    ")\n",
    "\n",
    "# Fit and transform the data\n",
    "vectorizer.fit(prompts + questions)\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Now the features should exclude non-English characters and numbers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abc</th>\n",
       "      <th>abcseries</th>\n",
       "      <th>ability</th>\n",
       "      <th>abiout</th>\n",
       "      <th>able</th>\n",
       "      <th>abs</th>\n",
       "      <th>absolute</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>accesing</th>\n",
       "      <th>...</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "      <th>ypred</th>\n",
       "      <th>yticklabels</th>\n",
       "      <th>yticks</th>\n",
       "      <th>zaman</th>\n",
       "      <th>zero</th>\n",
       "      <th>zerodivisionerror</th>\n",
       "      <th>zeroth</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 2632 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abc  abcseries  ability  abiout  able  abs  absolute  accept  acceptable  \\\n",
       "0  0.0        0.0      0.0     0.0   0.0  0.0       0.0     0.0         0.0   \n",
       "1  0.0        0.0      0.0     0.0   0.0  0.0       0.0     0.0         0.0   \n",
       "2  0.0        0.0      0.0     0.0   0.0  0.0       0.0     0.0         0.0   \n",
       "3  0.0        0.0      0.0     0.0   0.0  0.0       0.0     0.0         0.0   \n",
       "4  0.0        0.0      0.0     0.0   0.0  0.0       0.0     0.0         0.0   \n",
       "5  0.0        0.0      0.0     0.0   0.0  0.0       0.0     0.0         0.0   \n",
       "6  0.0        0.0      0.0     0.0   0.0  0.0       0.0     0.0         0.0   \n",
       "7  0.0        0.0      0.0     0.0   0.0  0.0       0.0     0.0         0.0   \n",
       "\n",
       "   accesing  ...  youre  youve  ypred  yticklabels  yticks  zaman  zero  \\\n",
       "0       0.0  ...    0.0    0.0    0.0          0.0     0.0    0.0   0.0   \n",
       "1       0.0  ...    0.0    0.0    0.0          0.0     0.0    0.0   0.0   \n",
       "2       0.0  ...    0.0    0.0    0.0          0.0     0.0    0.0   0.0   \n",
       "3       0.0  ...    0.0    0.0    0.0          0.0     0.0    0.0   0.0   \n",
       "4       0.0  ...    0.0    0.0    0.0          0.0     0.0    0.0   0.0   \n",
       "5       0.0  ...    0.0    0.0    0.0          0.0     0.0    0.0   0.0   \n",
       "6       0.0  ...    0.0    0.0    0.0          0.0     0.0    0.0   0.0   \n",
       "7       0.0  ...    0.0    0.0    0.0          0.0     0.0    0.0   0.0   \n",
       "\n",
       "   zerodivisionerror  zeroth  zip  \n",
       "0                0.0     0.0  0.0  \n",
       "1                0.0     0.0  0.0  \n",
       "2                0.0     0.0  0.0  \n",
       "3                0.0     0.0  0.0  \n",
       "4                0.0     0.0  0.0  \n",
       "5                0.0     0.0  0.0  \n",
       "6                0.0     0.0  0.0  \n",
       "7                0.0     0.0  0.0  \n",
       "\n",
       "[8 rows x 2632 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_TF_IDF = pd.DataFrame(vectorizer.transform(questions).toarray(), columns=vectorizer.get_feature_names_out())\n",
    "questions_TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\irfaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\irfaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>access</th>\n",
       "      <th>accomplished</th>\n",
       "      <th>according</th>\n",
       "      <th>accordingly</th>\n",
       "      <th>account</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yearly</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>yield</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeroth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1712 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability  able  absolute  accept  acceptable  access  accomplished  \\\n",
       "0      0.0   0.0       0.0     0.0         0.0     0.0           0.0   \n",
       "1      0.0   0.0       0.0     0.0         0.0     0.0           0.0   \n",
       "2      0.0   0.0       0.0     0.0         0.0     0.0           0.0   \n",
       "3      0.0   0.0       0.0     0.0         0.0     0.0           0.0   \n",
       "4      0.0   0.0       0.0     0.0         0.0     0.0           0.0   \n",
       "5      0.0   0.0       0.0     0.0         0.0     0.0           0.0   \n",
       "6      0.0   0.0       0.0     0.0         0.0     0.0           0.0   \n",
       "7      0.0   0.0       0.0     0.0         0.0     0.0           0.0   \n",
       "\n",
       "   according  accordingly  account  ...  wrong  wrote  yeah  year  yearly  \\\n",
       "0        0.0          0.0      0.0  ...    0.0    0.0   0.0   0.0     0.0   \n",
       "1        0.0          0.0      0.0  ...    0.0    0.0   0.0   0.0     0.0   \n",
       "2        0.0          0.0      0.0  ...    0.0    0.0   0.0   0.0     0.0   \n",
       "3        0.0          0.0      0.0  ...    0.0    0.0   0.0   0.0     0.0   \n",
       "4        0.0          0.0      0.0  ...    0.0    0.0   0.0   0.0     0.0   \n",
       "5        0.0          0.0      0.0  ...    0.0    0.0   0.0   0.0     0.0   \n",
       "6        0.0          0.0      0.0  ...    0.0    0.0   0.0   0.0     0.0   \n",
       "7        0.0          0.0      0.0  ...    0.0    0.0   0.0   0.0     0.0   \n",
       "\n",
       "   yes  yet  yield  zero  zeroth  \n",
       "0  0.0  0.0    0.0   0.0     0.0  \n",
       "1  0.0  0.0    0.0   0.0     0.0  \n",
       "2  0.0  0.0    0.0   0.0     0.0  \n",
       "3  0.0  0.0    0.0   0.0     0.0  \n",
       "4  0.0  0.0    0.0   0.0     0.0  \n",
       "5  0.0  0.0    0.0   0.0     0.0  \n",
       "6  0.0  0.0    0.0   0.0     0.0  \n",
       "7  0.0  0.0    0.0   0.0     0.0  \n",
       "\n",
       "[8 rows x 1712 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from spellchecker import SpellChecker\n",
    "# Download stopwords set\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "spell = SpellChecker()\n",
    "# Define a preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove short words\n",
    "    text = ' '.join([word for word in text.split() if len(word) > 2])\n",
    "    # Lemmatization and stop words removal\n",
    "    text = ' '.join([\n",
    "        lemmatizer.lemmatize(word) for word in text.split() \n",
    "        if word not in stopwords.words('english')\n",
    "    ])\n",
    "    # Tokenize the text\n",
    "    words = text.split()\n",
    "\n",
    "    # Only keep words that are spelled correctly\n",
    "    words = [word for word in words if word in spell or not spell.unknown([word])]\n",
    "\n",
    "    # Rejoin into a single string\n",
    "    text = ' '.join(words)\n",
    "    return text\n",
    "\n",
    "# Preprocess each prompt and question\n",
    "processed_prompts = [preprocess_text(prompt) for prompt in prompts]\n",
    "processed_questions = [preprocess_text(question) for question in questions]\n",
    "\n",
    "# Fit the vectorizer on the processed text with a strict token pattern\n",
    "token_pattern = r'\\b[a-zA-Z]{2,}\\b'  # Only English alphabetic characters\n",
    "vectorizer = TfidfVectorizer(lowercase=True, token_pattern=token_pattern)\n",
    "\n",
    "vectorizer.fit(processed_prompts + processed_questions)\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Transform the questions and convert to DataFrame\n",
    "questions_TF_IDF = pd.DataFrame(\n",
    "    vectorizer.transform(processed_questions).toarray(), \n",
    "    columns=features\n",
    ")\n",
    "\n",
    "# Manual filtering of non-English features\n",
    "english_feature_columns = [col for col in questions_TF_IDF.columns if re.fullmatch(r'[a-zA-Z]+', col)]\n",
    "questions_TF_IDF = questions_TF_IDF[english_feature_columns]\n",
    "questions_TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139235c7-736c-4237-92f0-92e8c116832c.html\n",
      "668ad17e-0240-49f7-b5a7-d22e502554c6.html\n",
      "b0640e51-6879-40cb-a4f5-329f952ef99d.html\n",
      "da6b70d5-29f6-491a-ad46-037c77067128.html\n"
     ]
    }
   ],
   "source": [
    "code2prompts_tf_idf = dict()\n",
    "\n",
    "for code, user_prompts in code2prompts.items():\n",
    "    if len(user_prompts) == 0:\n",
    "        # some files have issues\n",
    "        print(code+\".html\")\n",
    "        continue\n",
    "\n",
    "    # Apply the same preprocessing to user_prompts\n",
    "    processed_user_prompts = [preprocess_text(prompt) for prompt in user_prompts]\n",
    "\n",
    "    # Transform preprocessed prompts into TF-IDF matrix\n",
    "    prompts_TF_IDF = pd.DataFrame(\n",
    "        vectorizer.transform(processed_user_prompts).toarray(), \n",
    "        columns=vectorizer.get_feature_names_out()\n",
    "    )\n",
    "\n",
    "    code2prompts_tf_idf[code] = prompts_TF_IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>access</th>\n",
       "      <th>accomplished</th>\n",
       "      <th>according</th>\n",
       "      <th>accordingly</th>\n",
       "      <th>account</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yearly</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>yield</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeroth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 1712 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ability  able  absolute  accept  acceptable    access  accomplished  \\\n",
       "0       0.0   0.0       0.0     0.0         0.0  0.000000           0.0   \n",
       "1       0.0   0.0       0.0     0.0         0.0  0.000000           0.0   \n",
       "2       0.0   0.0       0.0     0.0         0.0  0.000000           0.0   \n",
       "3       0.0   0.0       0.0     0.0         0.0  0.000000           0.0   \n",
       "4       0.0   0.0       0.0     0.0         0.0  0.000000           0.0   \n",
       "5       0.0   0.0       0.0     0.0         0.0  0.000000           0.0   \n",
       "6       0.0   0.0       0.0     0.0         0.0  0.000000           0.0   \n",
       "7       0.0   0.0       0.0     0.0         0.0  0.000000           0.0   \n",
       "8       0.0   0.0       0.0     0.0         0.0  0.000000           0.0   \n",
       "9       0.0   0.0       0.0     0.0         0.0  0.000000           0.0   \n",
       "10      0.0   0.0       0.0     0.0         0.0  0.000000           0.0   \n",
       "11      0.0   0.0       0.0     0.0         0.0  0.216777           0.0   \n",
       "12      0.0   0.0       0.0     0.0         0.0  0.000000           0.0   \n",
       "13      0.0   0.0       0.0     0.0         0.0  0.000000           0.0   \n",
       "\n",
       "    according  accordingly  account  ...  wrong  wrote  yeah      year  \\\n",
       "0         0.0          0.0      0.0  ...    0.0    0.0   0.0  0.147995   \n",
       "1         0.0          0.0      0.0  ...    0.0    0.0   0.0  0.000000   \n",
       "2         0.0          0.0      0.0  ...    0.0    0.0   0.0  0.000000   \n",
       "3         0.0          0.0      0.0  ...    0.0    0.0   0.0  0.000000   \n",
       "4         0.0          0.0      0.0  ...    0.0    0.0   0.0  0.000000   \n",
       "5         0.0          0.0      0.0  ...    0.0    0.0   0.0  0.000000   \n",
       "6         0.0          0.0      0.0  ...    0.0    0.0   0.0  0.000000   \n",
       "7         0.0          0.0      0.0  ...    0.0    0.0   0.0  0.000000   \n",
       "8         0.0          0.0      0.0  ...    0.0    0.0   0.0  0.000000   \n",
       "9         0.0          0.0      0.0  ...    0.0    0.0   0.0  0.000000   \n",
       "10        0.0          0.0      0.0  ...    0.0    0.0   0.0  0.000000   \n",
       "11        0.0          0.0      0.0  ...    0.0    0.0   0.0  0.000000   \n",
       "12        0.0          0.0      0.0  ...    0.0    0.0   0.0  0.000000   \n",
       "13        0.0          0.0      0.0  ...    0.0    0.0   0.0  0.000000   \n",
       "\n",
       "    yearly  yes  yet  yield  zero  zeroth  \n",
       "0      0.0  0.0  0.0    0.0   0.0     0.0  \n",
       "1      0.0  0.0  0.0    0.0   0.0     0.0  \n",
       "2      0.0  0.0  0.0    0.0   0.0     0.0  \n",
       "3      0.0  0.0  0.0    0.0   0.0     0.0  \n",
       "4      0.0  0.0  0.0    0.0   0.0     0.0  \n",
       "5      0.0  0.0  0.0    0.0   0.0     0.0  \n",
       "6      0.0  0.0  0.0    0.0   0.0     0.0  \n",
       "7      0.0  0.0  0.0    0.0   0.0     0.0  \n",
       "8      0.0  0.0  0.0    0.0   0.0     0.0  \n",
       "9      0.0  0.0  0.0    0.0   0.0     0.0  \n",
       "10     0.0  0.0  0.0    0.0   0.0     0.0  \n",
       "11     0.0  0.0  0.0    0.0   0.0     0.0  \n",
       "12     0.0  0.0  0.0    0.0   0.0     0.0  \n",
       "13     0.0  0.0  0.0    0.0   0.0     0.0  \n",
       "\n",
       "[14 rows x 1712 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code2prompts_tf_idf[\"0031c86e-81f4-4eef-9e0e-28037abf9883\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "code2cosine = dict()\n",
    "for code, user_prompts_tf_idf in code2prompts_tf_idf.items():\n",
    "    code2cosine[code] = pd.DataFrame(cosine_similarity(questions_TF_IDF,user_prompts_tf_idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tune Hyperparameters (20 pts)\\n* Choose 2 hyperparameters to tune. You can use the Scikit learn decision tree documentation for the available hyperparameters *(Hyperparameters are listed under \"Parameters\" in the documentation)*. Use GridSearchCV for hyperparameter tuning, with a cross-validation value of 5. Use validation accuracy to pick the best hyper-parameter values. (15 pts)\\n-Explain the hyperparameters you chose to tune. *(What are the hyperparameters you chose? Why did you choose them?)* (5 pts)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>Q_0</th>\n",
       "      <th>Q_1</th>\n",
       "      <th>Q_2</th>\n",
       "      <th>Q_3</th>\n",
       "      <th>Q_4</th>\n",
       "      <th>Q_5</th>\n",
       "      <th>Q_6</th>\n",
       "      <th>Q_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0031c86e-81f4-4eef-9e0e-28037abf9883</td>\n",
       "      <td>1.512788</td>\n",
       "      <td>6.536609</td>\n",
       "      <td>1.498218</td>\n",
       "      <td>4.719384</td>\n",
       "      <td>10.390721</td>\n",
       "      <td>1.040977</td>\n",
       "      <td>2.941465</td>\n",
       "      <td>1.500968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0225686d-b825-4cac-8691-3a3a5343df2b</td>\n",
       "      <td>4.025933</td>\n",
       "      <td>11.711408</td>\n",
       "      <td>4.442972</td>\n",
       "      <td>6.128060</td>\n",
       "      <td>19.778232</td>\n",
       "      <td>12.978425</td>\n",
       "      <td>13.511586</td>\n",
       "      <td>7.398353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>041f950b-c013-409a-a642-cffff60b9d4b</td>\n",
       "      <td>0.822335</td>\n",
       "      <td>7.253650</td>\n",
       "      <td>1.412680</td>\n",
       "      <td>6.620465</td>\n",
       "      <td>5.764888</td>\n",
       "      <td>5.462287</td>\n",
       "      <td>9.157459</td>\n",
       "      <td>2.099878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04f91058-d0f8-4324-83b2-19c671f433dc</td>\n",
       "      <td>1.191679</td>\n",
       "      <td>4.358603</td>\n",
       "      <td>1.370156</td>\n",
       "      <td>4.838549</td>\n",
       "      <td>6.586580</td>\n",
       "      <td>1.858390</td>\n",
       "      <td>4.793643</td>\n",
       "      <td>5.331295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>089eb66d-4c3a-4f58-b98f-a3774a2efb34</td>\n",
       "      <td>3.144938</td>\n",
       "      <td>12.023740</td>\n",
       "      <td>3.483249</td>\n",
       "      <td>7.510627</td>\n",
       "      <td>17.205058</td>\n",
       "      <td>9.771592</td>\n",
       "      <td>18.295782</td>\n",
       "      <td>6.037874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>f24219d6-07f0-4baf-80ac-18475dc5b66f</td>\n",
       "      <td>0.837512</td>\n",
       "      <td>2.981328</td>\n",
       "      <td>0.972440</td>\n",
       "      <td>1.812653</td>\n",
       "      <td>7.361861</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>19.747111</td>\n",
       "      <td>8.343529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>f2f18684-4a16-4c05-a2d1-c0f96d1de869</td>\n",
       "      <td>0.385862</td>\n",
       "      <td>4.158578</td>\n",
       "      <td>4.710891</td>\n",
       "      <td>8.099867</td>\n",
       "      <td>16.639458</td>\n",
       "      <td>3.762250</td>\n",
       "      <td>17.273020</td>\n",
       "      <td>7.616351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>f852596d-fdca-45aa-9050-d4f76ce6a53c</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.662141</td>\n",
       "      <td>9.178980</td>\n",
       "      <td>18.169567</td>\n",
       "      <td>11.213542</td>\n",
       "      <td>18.694945</td>\n",
       "      <td>6.652278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>f8ec3336-fd48-4654-ad98-62ccfb96d096</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.386804</td>\n",
       "      <td>9.709553</td>\n",
       "      <td>16.930498</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7.716541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>fb8de815-224c-4d06-9fd4-7156d1a9920d</td>\n",
       "      <td>3.695508</td>\n",
       "      <td>12.135751</td>\n",
       "      <td>4.040316</td>\n",
       "      <td>9.558421</td>\n",
       "      <td>19.529657</td>\n",
       "      <td>14.712523</td>\n",
       "      <td>19.067419</td>\n",
       "      <td>8.273263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     code       Q_0        Q_1       Q_2  \\\n",
       "0    0031c86e-81f4-4eef-9e0e-28037abf9883  1.512788   6.536609  1.498218   \n",
       "1    0225686d-b825-4cac-8691-3a3a5343df2b  4.025933  11.711408  4.442972   \n",
       "2    041f950b-c013-409a-a642-cffff60b9d4b  0.822335   7.253650  1.412680   \n",
       "3    04f91058-d0f8-4324-83b2-19c671f433dc  1.191679   4.358603  1.370156   \n",
       "4    089eb66d-4c3a-4f58-b98f-a3774a2efb34  3.144938  12.023740  3.483249   \n",
       "..                                    ...       ...        ...       ...   \n",
       "118  f24219d6-07f0-4baf-80ac-18475dc5b66f  0.837512   2.981328  0.972440   \n",
       "119  f2f18684-4a16-4c05-a2d1-c0f96d1de869  0.385862   4.158578  4.710891   \n",
       "120  f852596d-fdca-45aa-9050-d4f76ce6a53c  5.000000  15.000000  4.662141   \n",
       "121  f8ec3336-fd48-4654-ad98-62ccfb96d096  5.000000  15.000000  3.386804   \n",
       "122  fb8de815-224c-4d06-9fd4-7156d1a9920d  3.695508  12.135751  4.040316   \n",
       "\n",
       "          Q_3        Q_4        Q_5        Q_6       Q_7  \n",
       "0    4.719384  10.390721   1.040977   2.941465  1.500968  \n",
       "1    6.128060  19.778232  12.978425  13.511586  7.398353  \n",
       "2    6.620465   5.764888   5.462287   9.157459  2.099878  \n",
       "3    4.838549   6.586580   1.858390   4.793643  5.331295  \n",
       "4    7.510627  17.205058   9.771592  18.295782  6.037874  \n",
       "..        ...        ...        ...        ...       ...  \n",
       "118  1.812653   7.361861  15.000000  19.747111  8.343529  \n",
       "119  8.099867  16.639458   3.762250  17.273020  7.616351  \n",
       "120  9.178980  18.169567  11.213542  18.694945  6.652278  \n",
       "121  9.709553  16.930498  15.000000  20.000000  7.716541  \n",
       "122  9.558421  19.529657  14.712523  19.067419  8.273263  \n",
       "\n",
       "[123 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code2questionmapping = dict()\n",
    "for code, cosine_scores in code2cosine.items():\n",
    "    code2questionmapping[code] = code2cosine[code].max(axis=1).tolist()\n",
    "\n",
    "\n",
    "question_mapping_scores = pd.DataFrame(code2questionmapping).T\n",
    "question_mapping_scores.reset_index(inplace=True)\n",
    "question_mapping_scores.rename(columns={i: f\"Q_{i}\" for i in range(len(questions))}, inplace=True)\n",
    "question_mapping_scores.rename(columns={\"index\" : \"code\"}, inplace=True)\n",
    "\n",
    "\n",
    "# Define the weights for each question based on their contribution to the overall grade.\n",
    "weights = [ 5, 15, 5, 10, 20, 15, 20, 10]\n",
    "\n",
    "# Assuming 'question_mapping_scores' is your DataFrame and it's already loaded.\n",
    "# Apply the weights to each column (excluding the 'code' column).\n",
    "for i, weight in enumerate(weights):\n",
    "    question_mapping_scores[f'Q_{i}'] *= weight\n",
    "\n",
    "question_mapping_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "- Number of prompts that a users asked\n",
    "- Number of complaints that a user makes e.g \"the code gives this error!\"\n",
    "- User prompts average number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139235c7-736c-4237-92f0-92e8c116832c\n",
      "668ad17e-0240-49f7-b5a7-d22e502554c6\n",
      "b0640e51-6879-40cb-a4f5-329f952ef99d\n",
      "da6b70d5-29f6-491a-ad46-037c77067128\n"
     ]
    }
   ],
   "source": [
    "code2features = defaultdict(lambda : defaultdict(int))\n",
    "\n",
    "keywords2search = [\"error\", \"no\", \"thank\", \"next\", \"Entropy\", \"Hyperparameter\", \"Hypothetical features\"]\n",
    "keywords2search = [k.lower() for k in keywords2search]\n",
    "\n",
    "for code, convs in code2convos.items():\n",
    "    if len(convs) == 0:\n",
    "        print(code)\n",
    "        continue\n",
    "    for c in convs:\n",
    "        text = c[\"text\"].lower()\n",
    "        if c[\"role\"] == \"user\":\n",
    "            # User Prompts\n",
    "\n",
    "            # count the user prompts\n",
    "            code2features[code][\"#user_prompts\"] += 1\n",
    "            \n",
    "            # count the keywords\n",
    "            for kw in keywords2search:\n",
    "                code2features[code][f\"#{kw}\"] +=  len(re.findall(rf\"\\b{kw}\\b\", text))\n",
    "\n",
    "            code2features[code][\"prompt_avg_chars\"] += len(text)\n",
    "        else:\n",
    "            # ChatGPT Responses\n",
    "            code2features[code][\"response_avg_chars\"] += len(text)\n",
    "\n",
    "        code2features[code][\"prompt_avg_chars\"] /= code2features[code][\"#user_prompts\"]   \n",
    "        # code2features[code][\"response_avg_chars\"] /= code2features[code][\"#user_prompts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#user_prompts</th>\n",
       "      <th>#error</th>\n",
       "      <th>#no</th>\n",
       "      <th>#thank</th>\n",
       "      <th>#next</th>\n",
       "      <th>#entropy</th>\n",
       "      <th>#hyperparameter</th>\n",
       "      <th>#hypothetical features</th>\n",
       "      <th>prompt_avg_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0031c86e-81f4-4eef-9e0e-28037abf9883</th>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.102124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0225686d-b825-4cac-8691-3a3a5343df2b</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.991354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>041f950b-c013-409a-a642-cffff60b9d4b</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.907994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04f91058-d0f8-4324-83b2-19c671f433dc</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.776954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089eb66d-4c3a-4f58-b98f-a3774a2efb34</th>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.569760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      #user_prompts  #error  #no  #thank  \\\n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883           14.0     3.0  1.0     0.0   \n",
       "0225686d-b825-4cac-8691-3a3a5343df2b           18.0     0.0  0.0     0.0   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b            9.0     3.0  0.0     1.0   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc           20.0     1.0  1.0     0.0   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34           86.0     1.0  5.0     0.0   \n",
       "\n",
       "                                      #next  #entropy  #hyperparameter  \\\n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883    0.0       0.0              0.0   \n",
       "0225686d-b825-4cac-8691-3a3a5343df2b    0.0       3.0              2.0   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b    0.0       3.0              1.0   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc    0.0       3.0              0.0   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34    0.0      26.0              2.0   \n",
       "\n",
       "                                      #hypothetical features  prompt_avg_chars  \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                     1.0         32.102124  \n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                     1.0          5.991354  \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                     2.0          4.907994  \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                     1.0          2.776954  \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                     2.0          1.569760  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(code2features).T\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   code  grade\n",
      "0  6a2003ad-a05a-41c9-9d48-e98491a90499   90.0\n",
      "1  04f91058-d0f8-4324-83b2-19c671f433dc   97.0\n",
      "2  81fdeb2a-e7e5-4a05-8058-d31ea579b0d9   94.0\n",
      "3  6a903495-c5be-4263-b4dd-75e2bbc30434   97.0\n",
      "4  6d5742c1-77c4-429c-8f6e-ef1262ca5557   93.0\n",
      "['6312a21b-c6be-44f9-ad81-46307b339fb6', '6b4e988c-eead-46ff-a35b-b2fd325b2698', '6b4e988c-eead-46ff-a35b-b2fd325b2698', '745ffa9e-f540-488a-b752-a3add11cb30b', 'e8fd2278-1620-432d-81cb-02cac8543456', '42980d53-7bcd-4a36-bf3a-aa43f7417ac5', 'da219169-aacb-48b8-abdc-e25f08ad029e', '0031c86e-81f4-4eef-9e0e-28037abf9883', '5e481e20-f714-4f11-b941-0ef2fd5976d3', 'b24c3a33-2952-4ae4-9f2d-643d8fdbc600']\n"
     ]
    }
   ],
   "source": [
    "# reading the scores\n",
    "scores = pd.read_csv(\"scores.csv\", sep=\",\")\n",
    "scores[\"code\"] = scores[\"code\"].apply(lambda x: x.strip())\n",
    "\n",
    "# selecting the columns we need and we care\n",
    "scores = scores[[\"code\", \"grade\"]]\n",
    "\n",
    "# show some examples\n",
    "print(scores.head())\n",
    "\n",
    "codes_below_50 = scores[scores[\"grade\"] < 80][\"code\"].tolist()\n",
    "print(codes_below_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check grades distribution\n",
    "\n",
    "plt.title('Histogram Grades')\n",
    "plt.hist(scores[\"grade\"], rwidth=.8, bins=np.arange(min(scores[\"grade\"]), max(scores[\"grade\"])+2) - 0.5)\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>#user_prompts</th>\n",
       "      <th>#error</th>\n",
       "      <th>#no</th>\n",
       "      <th>#thank</th>\n",
       "      <th>#next</th>\n",
       "      <th>#entropy</th>\n",
       "      <th>#hyperparameter</th>\n",
       "      <th>#hypothetical features</th>\n",
       "      <th>prompt_avg_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0031c86e-81f4-4eef-9e0e-28037abf9883</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.102124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0225686d-b825-4cac-8691-3a3a5343df2b</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.991354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>041f950b-c013-409a-a642-cffff60b9d4b</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.907994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04f91058-d0f8-4324-83b2-19c671f433dc</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.776954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>089eb66d-4c3a-4f58-b98f-a3774a2efb34</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.569760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   code  #user_prompts  #error  #no  #thank  \\\n",
       "0  0031c86e-81f4-4eef-9e0e-28037abf9883           14.0     3.0  1.0     0.0   \n",
       "1  0225686d-b825-4cac-8691-3a3a5343df2b           18.0     0.0  0.0     0.0   \n",
       "2  041f950b-c013-409a-a642-cffff60b9d4b            9.0     3.0  0.0     1.0   \n",
       "3  04f91058-d0f8-4324-83b2-19c671f433dc           20.0     1.0  1.0     0.0   \n",
       "4  089eb66d-4c3a-4f58-b98f-a3774a2efb34           86.0     1.0  5.0     0.0   \n",
       "\n",
       "   #next  #entropy  #hyperparameter  #hypothetical features  prompt_avg_chars  \n",
       "0    0.0       0.0              0.0                     1.0         32.102124  \n",
       "1    0.0       3.0              2.0                     1.0          5.991354  \n",
       "2    0.0       3.0              1.0                     2.0          4.907994  \n",
       "3    0.0       3.0              0.0                     1.0          2.776954  \n",
       "4    0.0      26.0              2.0                     2.0          1.569760  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(inplace=True, drop=False)\n",
    "df.rename(columns={\"index\": \"code\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>#user_prompts</th>\n",
       "      <th>#error</th>\n",
       "      <th>#no</th>\n",
       "      <th>#thank</th>\n",
       "      <th>#next</th>\n",
       "      <th>#entropy</th>\n",
       "      <th>#hyperparameter</th>\n",
       "      <th>#hypothetical features</th>\n",
       "      <th>prompt_avg_chars</th>\n",
       "      <th>Q_0</th>\n",
       "      <th>Q_1</th>\n",
       "      <th>Q_2</th>\n",
       "      <th>Q_3</th>\n",
       "      <th>Q_4</th>\n",
       "      <th>Q_5</th>\n",
       "      <th>Q_6</th>\n",
       "      <th>Q_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0031c86e-81f4-4eef-9e0e-28037abf9883</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.102124</td>\n",
       "      <td>1.512788</td>\n",
       "      <td>6.536609</td>\n",
       "      <td>1.498218</td>\n",
       "      <td>4.719384</td>\n",
       "      <td>10.390721</td>\n",
       "      <td>1.040977</td>\n",
       "      <td>2.941465</td>\n",
       "      <td>1.500968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0225686d-b825-4cac-8691-3a3a5343df2b</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.991354</td>\n",
       "      <td>4.025933</td>\n",
       "      <td>11.711408</td>\n",
       "      <td>4.442972</td>\n",
       "      <td>6.128060</td>\n",
       "      <td>19.778232</td>\n",
       "      <td>12.978425</td>\n",
       "      <td>13.511586</td>\n",
       "      <td>7.398353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>041f950b-c013-409a-a642-cffff60b9d4b</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.907994</td>\n",
       "      <td>0.822335</td>\n",
       "      <td>7.253650</td>\n",
       "      <td>1.412680</td>\n",
       "      <td>6.620465</td>\n",
       "      <td>5.764888</td>\n",
       "      <td>5.462287</td>\n",
       "      <td>9.157459</td>\n",
       "      <td>2.099878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04f91058-d0f8-4324-83b2-19c671f433dc</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.776954</td>\n",
       "      <td>1.191679</td>\n",
       "      <td>4.358603</td>\n",
       "      <td>1.370156</td>\n",
       "      <td>4.838549</td>\n",
       "      <td>6.586580</td>\n",
       "      <td>1.858390</td>\n",
       "      <td>4.793643</td>\n",
       "      <td>5.331295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>089eb66d-4c3a-4f58-b98f-a3774a2efb34</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.569760</td>\n",
       "      <td>3.144938</td>\n",
       "      <td>12.023740</td>\n",
       "      <td>3.483249</td>\n",
       "      <td>7.510627</td>\n",
       "      <td>17.205058</td>\n",
       "      <td>9.771592</td>\n",
       "      <td>18.295782</td>\n",
       "      <td>6.037874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   code  #user_prompts  #error  #no  #thank  \\\n",
       "0  0031c86e-81f4-4eef-9e0e-28037abf9883           14.0     3.0  1.0     0.0   \n",
       "1  0225686d-b825-4cac-8691-3a3a5343df2b           18.0     0.0  0.0     0.0   \n",
       "2  041f950b-c013-409a-a642-cffff60b9d4b            9.0     3.0  0.0     1.0   \n",
       "3  04f91058-d0f8-4324-83b2-19c671f433dc           20.0     1.0  1.0     0.0   \n",
       "4  089eb66d-4c3a-4f58-b98f-a3774a2efb34           86.0     1.0  5.0     0.0   \n",
       "\n",
       "   #next  #entropy  #hyperparameter  #hypothetical features  prompt_avg_chars  \\\n",
       "0    0.0       0.0              0.0                     1.0         32.102124   \n",
       "1    0.0       3.0              2.0                     1.0          5.991354   \n",
       "2    0.0       3.0              1.0                     2.0          4.907994   \n",
       "3    0.0       3.0              0.0                     1.0          2.776954   \n",
       "4    0.0      26.0              2.0                     2.0          1.569760   \n",
       "\n",
       "        Q_0        Q_1       Q_2       Q_3        Q_4        Q_5        Q_6  \\\n",
       "0  1.512788   6.536609  1.498218  4.719384  10.390721   1.040977   2.941465   \n",
       "1  4.025933  11.711408  4.442972  6.128060  19.778232  12.978425  13.511586   \n",
       "2  0.822335   7.253650  1.412680  6.620465   5.764888   5.462287   9.157459   \n",
       "3  1.191679   4.358603  1.370156  4.838549   6.586580   1.858390   4.793643   \n",
       "4  3.144938  12.023740  3.483249  7.510627  17.205058   9.771592  18.295782   \n",
       "\n",
       "        Q_7  \n",
       "0  1.500968  \n",
       "1  7.398353  \n",
       "2  2.099878  \n",
       "3  5.331295  \n",
       "4  6.037874  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, question_mapping_scores, on=\"code\", how=\"left\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging scores with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>#user_prompts</th>\n",
       "      <th>#error</th>\n",
       "      <th>#no</th>\n",
       "      <th>#thank</th>\n",
       "      <th>#next</th>\n",
       "      <th>#entropy</th>\n",
       "      <th>#hyperparameter</th>\n",
       "      <th>#hypothetical features</th>\n",
       "      <th>prompt_avg_chars</th>\n",
       "      <th>Q_0</th>\n",
       "      <th>Q_1</th>\n",
       "      <th>Q_2</th>\n",
       "      <th>Q_3</th>\n",
       "      <th>Q_4</th>\n",
       "      <th>Q_5</th>\n",
       "      <th>Q_6</th>\n",
       "      <th>Q_7</th>\n",
       "      <th>grade</th>\n",
       "      <th>code_responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0031c86e-81f4-4eef-9e0e-28037abf9883</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.102124</td>\n",
       "      <td>1.512788</td>\n",
       "      <td>6.536609</td>\n",
       "      <td>1.498218</td>\n",
       "      <td>4.719384</td>\n",
       "      <td>10.390721</td>\n",
       "      <td>1.040977</td>\n",
       "      <td>2.941465</td>\n",
       "      <td>1.500968</td>\n",
       "      <td>48.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0225686d-b825-4cac-8691-3a3a5343df2b</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.991354</td>\n",
       "      <td>4.025933</td>\n",
       "      <td>11.711408</td>\n",
       "      <td>4.442972</td>\n",
       "      <td>6.128060</td>\n",
       "      <td>19.778232</td>\n",
       "      <td>12.978425</td>\n",
       "      <td>13.511586</td>\n",
       "      <td>7.398353</td>\n",
       "      <td>99.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>041f950b-c013-409a-a642-cffff60b9d4b</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.907994</td>\n",
       "      <td>0.822335</td>\n",
       "      <td>7.253650</td>\n",
       "      <td>1.412680</td>\n",
       "      <td>6.620465</td>\n",
       "      <td>5.764888</td>\n",
       "      <td>5.462287</td>\n",
       "      <td>9.157459</td>\n",
       "      <td>2.099878</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04f91058-d0f8-4324-83b2-19c671f433dc</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.776954</td>\n",
       "      <td>1.191679</td>\n",
       "      <td>4.358603</td>\n",
       "      <td>1.370156</td>\n",
       "      <td>4.838549</td>\n",
       "      <td>6.586580</td>\n",
       "      <td>1.858390</td>\n",
       "      <td>4.793643</td>\n",
       "      <td>5.331295</td>\n",
       "      <td>97.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>089eb66d-4c3a-4f58-b98f-a3774a2efb34</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.569760</td>\n",
       "      <td>3.144938</td>\n",
       "      <td>12.023740</td>\n",
       "      <td>3.483249</td>\n",
       "      <td>7.510627</td>\n",
       "      <td>17.205058</td>\n",
       "      <td>9.771592</td>\n",
       "      <td>18.295782</td>\n",
       "      <td>6.037874</td>\n",
       "      <td>100.0</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>f24219d6-07f0-4baf-80ac-18475dc5b66f</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.583692</td>\n",
       "      <td>0.837512</td>\n",
       "      <td>2.981328</td>\n",
       "      <td>0.972440</td>\n",
       "      <td>1.812653</td>\n",
       "      <td>7.361861</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>19.747111</td>\n",
       "      <td>8.343529</td>\n",
       "      <td>93.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>f2f18684-4a16-4c05-a2d1-c0f96d1de869</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.580530</td>\n",
       "      <td>0.385862</td>\n",
       "      <td>4.158578</td>\n",
       "      <td>4.710891</td>\n",
       "      <td>8.099867</td>\n",
       "      <td>16.639458</td>\n",
       "      <td>3.762250</td>\n",
       "      <td>17.273020</td>\n",
       "      <td>7.616351</td>\n",
       "      <td>100.0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>f852596d-fdca-45aa-9050-d4f76ce6a53c</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.177291</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.662141</td>\n",
       "      <td>9.178980</td>\n",
       "      <td>18.169567</td>\n",
       "      <td>11.213542</td>\n",
       "      <td>18.694945</td>\n",
       "      <td>6.652278</td>\n",
       "      <td>98.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>f8ec3336-fd48-4654-ad98-62ccfb96d096</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.071781</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.386804</td>\n",
       "      <td>9.709553</td>\n",
       "      <td>16.930498</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7.716541</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>fb8de815-224c-4d06-9fd4-7156d1a9920d</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.089966</td>\n",
       "      <td>3.695508</td>\n",
       "      <td>12.135751</td>\n",
       "      <td>4.040316</td>\n",
       "      <td>9.558421</td>\n",
       "      <td>19.529657</td>\n",
       "      <td>14.712523</td>\n",
       "      <td>19.067419</td>\n",
       "      <td>8.273263</td>\n",
       "      <td>98.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     code  #user_prompts  #error  #no  #thank  \\\n",
       "0    0031c86e-81f4-4eef-9e0e-28037abf9883           14.0     3.0  1.0     0.0   \n",
       "1    0225686d-b825-4cac-8691-3a3a5343df2b           18.0     0.0  0.0     0.0   \n",
       "2    041f950b-c013-409a-a642-cffff60b9d4b            9.0     3.0  0.0     1.0   \n",
       "3    04f91058-d0f8-4324-83b2-19c671f433dc           20.0     1.0  1.0     0.0   \n",
       "4    089eb66d-4c3a-4f58-b98f-a3774a2efb34           86.0     1.0  5.0     0.0   \n",
       "..                                    ...            ...     ...  ...     ...   \n",
       "135  f24219d6-07f0-4baf-80ac-18475dc5b66f           21.0     1.0  0.0     0.0   \n",
       "136  f2f18684-4a16-4c05-a2d1-c0f96d1de869           71.0     1.0  1.0     1.0   \n",
       "137  f852596d-fdca-45aa-9050-d4f76ce6a53c           30.0     6.0  1.0     0.0   \n",
       "138  f8ec3336-fd48-4654-ad98-62ccfb96d096           14.0     0.0  0.0     0.0   \n",
       "139  fb8de815-224c-4d06-9fd4-7156d1a9920d           31.0     8.0  0.0     2.0   \n",
       "\n",
       "     #next  #entropy  #hyperparameter  #hypothetical features  \\\n",
       "0      0.0       0.0              0.0                     1.0   \n",
       "1      0.0       3.0              2.0                     1.0   \n",
       "2      0.0       3.0              1.0                     2.0   \n",
       "3      0.0       3.0              0.0                     1.0   \n",
       "4      0.0      26.0              2.0                     2.0   \n",
       "..     ...       ...              ...                     ...   \n",
       "135    0.0       4.0              1.0                     0.0   \n",
       "136    1.0       6.0              1.0                     3.0   \n",
       "137    4.0       3.0              1.0                    10.0   \n",
       "138    1.0       3.0              1.0                     1.0   \n",
       "139    0.0       7.0              1.0                     1.0   \n",
       "\n",
       "     prompt_avg_chars       Q_0        Q_1       Q_2       Q_3        Q_4  \\\n",
       "0           32.102124  1.512788   6.536609  1.498218  4.719384  10.390721   \n",
       "1            5.991354  4.025933  11.711408  4.442972  6.128060  19.778232   \n",
       "2            4.907994  0.822335   7.253650  1.412680  6.620465   5.764888   \n",
       "3            2.776954  1.191679   4.358603  1.370156  4.838549   6.586580   \n",
       "4            1.569760  3.144938  12.023740  3.483249  7.510627  17.205058   \n",
       "..                ...       ...        ...       ...       ...        ...   \n",
       "135          2.583692  0.837512   2.981328  0.972440  1.812653   7.361861   \n",
       "136          8.580530  0.385862   4.158578  4.710891  8.099867  16.639458   \n",
       "137          3.177291  5.000000  15.000000  4.662141  9.178980  18.169567   \n",
       "138          3.071781  5.000000  15.000000  3.386804  9.709553  16.930498   \n",
       "139         14.089966  3.695508  12.135751  4.040316  9.558421  19.529657   \n",
       "\n",
       "           Q_5        Q_6       Q_7  grade  code_responses  \n",
       "0     1.040977   2.941465  1.500968   48.0              14  \n",
       "1    12.978425  13.511586  7.398353   99.0              17  \n",
       "2     5.462287   9.157459  2.099878   90.0               7  \n",
       "3     1.858390   4.793643  5.331295   97.0              19  \n",
       "4     9.771592  18.295782  6.037874  100.0              82  \n",
       "..         ...        ...       ...    ...             ...  \n",
       "135  15.000000  19.747111  8.343529   93.0              16  \n",
       "136   3.762250  17.273020  7.616351  100.0              59  \n",
       "137  11.213542  18.694945  6.652278   98.0              25  \n",
       "138  15.000000  20.000000  7.716541  100.0              14  \n",
       "139  14.712523  19.067419  8.273263   98.0              30  \n",
       "\n",
       "[122 rows x 20 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.merge(df, scores, on='code', how=\"left\")\n",
    "temp_df = pd.merge(temp_df, total_code_response_df, on='code', how='left')\n",
    "temp_df.dropna(inplace=True)\n",
    "temp_df.drop_duplicates(\"code\",inplace=True, keep=\"first\")\n",
    "#temp_df = temp_df[~temp_df['code'].isin(codes_below_50)]\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 18) (122,)\n"
     ]
    }
   ],
   "source": [
    "X = temp_df[temp_df.columns[1:-1]].to_numpy()\n",
    "y = temp_df[\"grade\"].to_numpy()\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 97\n",
      "Test set size: 25\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Train set size:\", len(X_train))\n",
    "print(\"Test set size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting and Analyzing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = DecisionTreeRegressor(random_state=0,criterion='squared_error', max_depth=10)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 has MSE 163.42034222552866\n",
      "Node 1 has MSE 216.8888888888887\n",
      "Node 2 has MSE 64.0\n",
      "Node 3 has MSE 0.0\n",
      "Node 4 has MSE 0.0\n",
      "Node 5 has MSE 0.0\n",
      "Node 6 has MSE 45.800362154819595\n",
      "Node 7 has MSE 26.246913580247565\n",
      "Node 8 has MSE 10.639999999999418\n",
      "Node 9 has MSE 1.0\n",
      "Node 10 has MSE 0.0\n",
      "Node 11 has MSE 0.0\n",
      "Node 12 has MSE 2.66666666666697\n",
      "Node 13 has MSE 0.0\n",
      "Node 14 has MSE 1.0\n",
      "Node 15 has MSE 0.0\n",
      "Node 16 has MSE 0.0\n",
      "Node 17 has MSE 6.977272727272975\n",
      "Node 18 has MSE 1.3254437869809408\n",
      "Node 19 has MSE 0.5306122448982933\n",
      "Node 20 has MSE 0.25\n",
      "Node 21 has MSE 0.0\n",
      "Node 22 has MSE 0.0\n",
      "Node 23 has MSE 0.0\n",
      "Node 24 has MSE 0.25\n",
      "Node 25 has MSE 0.0\n",
      "Node 26 has MSE 0.0\n",
      "Node 27 has MSE 0.46913580246928177\n",
      "Node 28 has MSE 0.1875\n",
      "Node 29 has MSE 0.0\n",
      "Node 30 has MSE 0.0\n",
      "Node 31 has MSE 0.0\n",
      "Node 32 has MSE 6.770773000667759\n",
      "Node 33 has MSE 1.9199999999982538\n",
      "Node 34 has MSE 0.8402366863901989\n",
      "Node 35 has MSE 0.22222222222080745\n",
      "Node 36 has MSE 0.0\n",
      "Node 37 has MSE 0.0\n",
      "Node 38 has MSE 0.25\n",
      "Node 39 has MSE 0.0\n",
      "Node 40 has MSE 0.0\n",
      "Node 41 has MSE 0.24305555555474712\n",
      "Node 42 has MSE 0.0\n",
      "Node 43 has MSE 0.0\n",
      "Node 44 has MSE 0.9756235827680939\n",
      "Node 45 has MSE 0.22222222222080745\n",
      "Node 46 has MSE 0.0\n",
      "Node 47 has MSE 0.0\n",
      "Node 48 has MSE 0.24555555555525643\n",
      "Node 49 has MSE 0.0\n",
      "Node 50 has MSE 0.0\n"
     ]
    }
   ],
   "source": [
    "extracted_MSEs = regressor.tree_.impurity   \n",
    "for idx, MSE in enumerate(regressor.tree_.impurity):\n",
    "    print(\"Node {} has MSE {}\".format(idx,MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hw.pdf'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotting the Tree \n",
    "dot_data = tree.export_graphviz(regressor, out_file=None, feature_names=temp_df.columns[1:-1])\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"hw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train: 0.0\n",
      "MSE TEST: 13.6\n",
      "R2 Train: 1.0\n",
      "R2 TEST: 0.8788587064960237\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "y_train_pred = regressor.predict(X_train)\n",
    "y_test_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculation of Mean Squared Error (MSE)\n",
    "print(\"MSE Train:\", mean_squared_error(y_train,y_train_pred))\n",
    "print(\"MSE TEST:\", mean_squared_error(y_test,y_test_pred))\n",
    "\n",
    "print(\"R2 Train:\", r2_score(y_train,y_train_pred))\n",
    "print(\"R2 TEST:\", r2_score(y_test,y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "### 1) KMeans Clustering\n",
    "Firstly, we will create an algorithm to find the best value for K. Then, we will use this to plot and analyse the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Number of Clusters: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def find_optimal_clusters(data, max_clusters=10):\n",
    "\n",
    "    # Feature scaling \n",
    "    # Can possibly try other scaler as well(minmax,etc?)\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "    silhouette_scores = [] #used to determine optimal number of cluster\n",
    "\n",
    "    for k in range(2, max_clusters + 1):\n",
    "        # Apply K-Means clustering\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        cluster_assignments = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "        # Calculate silhouette score\n",
    "        silhouette_avg = silhouette_score(data_scaled, cluster_assignments)\n",
    "        silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "    # Find the optimal number of clusters with the highest silhouette score\n",
    "    optimal_clusters = silhouette_scores.index(max(silhouette_scores)) + 2  # Add 2 because we started with k=2\n",
    "\n",
    "    return optimal_clusters, silhouette_scores, cluster_assignments\n",
    "\n",
    "# Selecting relevant features for clustering\n",
    "# We will include all of the collumns except the identifier, aka the code\n",
    "X = temp_df[temp_df.columns[1:]].to_numpy()\n",
    "\n",
    "# Find the optimal number of clusters\n",
    "optimal_clusters, silhouette_scores, cluster_assignments = find_optimal_clusters(X, max_clusters=10)\n",
    "\n",
    "# Visualize silhouette scores\n",
    "plt.plot(range(2, 11), silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score for Different Numbers of Clusters')\n",
    "plt.show()\n",
    "\n",
    "print(f'Optimal Number of Clusters: {optimal_clusters}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# using the merged df from above\n",
    "X = temp_df[temp_df.columns[1:]].to_numpy()\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# optimal number of cluster\n",
    "k = 2\n",
    "\n",
    "# Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "cluster_assignments = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Visualize clusters using scatter plot\n",
    "\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=cluster_assignments, cmap='viridis')\n",
    "plt.title('K-Means Clustering')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.2397843663413637\n"
     ]
    }
   ],
   "source": [
    "# Silhouette score\n",
    "silhouette_avg = silhouette_score(X_scaled, cluster_assignments)\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\irfaa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choosing the second most optimal\n",
    "k = 4\n",
    "\n",
    "# Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "cluster_assignments = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Visualize clusters (for example, using a scatter plot)\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=cluster_assignments, cmap='viridis')\n",
    "plt.title('K-Means Clustering')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.22900196465936912\n"
     ]
    }
   ],
   "source": [
    "# Silhouette score\n",
    "silhouette_avg = silhouette_score(X_scaled, cluster_assignments)\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "The silhouette score from using KMeans is relatively small. It suggests that the clusters have some degree of separation, but there might be areas of overlap or ambiguity. This claim is also supported by the visualization of the KMeans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "### 2) DBScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extracting the same features as above\n",
    "X = temp_df[temp_df.columns[1:]].to_numpy()\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply DBSCAN clustering\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)  # Adjust parameters as needed\n",
    "cluster_assignments = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "# Visualize clusters\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=cluster_assignments, cmap='viridis')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "There is only one cluster. Thus, we cannot apply silhoutte score to measure the compactness. Furthermore, it shows that the dataset is not seperable using DBScan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
